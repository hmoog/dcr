\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage[margin=2.5cm]{geometry}
\usepackage{natbib}
\usepackage{enumitem}
\usepackage{microtype}

% Theorem environments
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]

% Operators
\DeclareMathOperator{\Coh}{Coh}
\DeclareMathOperator{\Ent}{H}
\DeclareMathOperator{\Viol}{V}

\title{%
  Distributed Constraint Resolution as Universal Cognition:\\
  A Scale-Free Framework Unifying Physics and Intelligence%
}
\author{%
  [Author]\\
  {\small [Affiliation]}\\
  {\small [Email]}
}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
We propose a formal framework in which cognition is identified with
a universal process: the exploration of degrees of freedom followed by
convergence through distributed constraint resolution into coherent,
goal-stabilizing patterns. We formalize this triad---\emph{exploration},
\emph{resolution}, and \emph{stabilization}---using dynamical systems
on constraint networks equipped with an information-theoretic coherence
measure. We prove that, under a timescale separation condition, the
framework is closed under coarse-graining: a coarse-graining construction
maps cognitive systems at one scale to cognitive systems at the next,
dissolving the combination problem that plagues panpsychist theories.
We show that the Free Energy Principle and
Integrated Information Theory arise as special cases corresponding to
particular choices of constraint structure and coherence measure. By
demonstrating that fundamental physical processes---quantum transactions,
thermodynamic self-organization, and biological adaptation---satisfy the
framework's axioms, we argue that the cosmos is cognitive at every scale,
and that what we colloquially call ``intelligence'' is a particularly
deep nesting of this universal process. We further connect the framework
to recent discrete-ontic models of quantum mechanics, arguing that the
continuum of standard physics may itself emerge from finite combinatorial
constraint resolution.
\end{abstract}

\paragraph{Keywords:} cognition, intelligence, constraint resolution, free energy
principle, integrated information, scale-free, coarse-graining, self-organization

% ==========================================================================
\section{Introduction}\label{sec:introduction}
% ==========================================================================

The search for a general, principled definition of intelligence remains one of
the deepest open problems across cognitive science, physics, and philosophy of
mind. Existing frameworks each illuminate a facet of the problem but fall short
of universality:

\begin{itemize}[nosep]
  \item The \emph{Free Energy Principle} (FEP) \citep{friston2010free,
        friston2019free} provides an elegant variational account: any system
        persisting at nonequilibrium steady state minimizes variational free
        energy. Yet FEP assumes a Markov blanket separating system from
        environment and a generative model as primitives
        \citep{kirchhoff2018markov}, limiting its applicability to systems
        where these structures can be identified.
  \item \emph{Integrated Information Theory} (IIT)
        \citep{tononi2004information, tononi2016integrated} offers a quantitative
        measure of consciousness ($\Phi$), but in its original formulations
        (IIT~2.0/3.0) it is a static, state-level measure rather than a
        process-level account\footnote{IIT~4.0 introduces dynamical
        considerations that partially address this limitation; see
        \cref{ssec:iit-recovery} for discussion.}, and its computation is
        intractable for large systems.
  \item \emph{Autopoiesis} \citep{maturana1980autopoiesis} captures
        self-production but lacks formal predictive content beyond the
        biological domain.
  \item \emph{Panpsychism} \citep{chalmers1995facing} attributes experience to
        fundamental entities but provides no mechanism and no solution to the
        combination problem---how micro-experiences compose into
        macro-experiences.
\end{itemize}

We propose that these limitations stem from a common root: each framework
privileges a particular \emph{level of description} (Bayesian inference,
information integration, self-production) rather than identifying the
\emph{scale-free process} that underlies all of them.

Our central thesis:

\begin{quote}
\emph{Intelligent behavior emerges when components explore degrees of freedom
and converge through distributed constraint resolution into coherent,
goal-stabilizing patterns.}
\end{quote}

We call this the \textbf{Distributed Constraint Resolution} (DCR) framework.
The key claim is that this triad---exploration, resolution,
stabilization---constitutes the \emph{minimal and universal} signature of
cognition, and that it is realized by physical law itself at every scale.

The paper is organized as follows. \Cref{sec:framework} formalizes the DCR
framework. \Cref{sec:scale-free} proves closure under coarse-graining (given
timescale separation), dissolving the combination problem.
\Cref{sec:physics} demonstrates that fundamental physical processes satisfy
the DCR axioms. \Cref{sec:recovery} recovers FEP and IIT as special cases.
\Cref{sec:predictions} derives falsifiable predictions. \Cref{sec:discussion}
discusses implications and limitations.

% ==========================================================================
\section{The DCR Framework}\label{sec:framework}
% ==========================================================================

\subsection{Constraint Networks}\label{ssec:constraint-networks}

\begin{definition}[Constraint Network]\label{def:constraint-network}
A \emph{constraint network} is a tuple $\mathcal{N} = (S, \mathcal{D}, G, \mathcal{R})$
where:
\begin{enumerate}[nosep]
  \item $S$ is a finite set of \emph{components}.
  \item $\mathcal{D} = \{D_s\}_{s \in S}$ assigns to each component $s$ a
        measurable \emph{state space} $D_s$ (its degrees of freedom).
  \item $G = (S, E)$ is an undirected graph encoding the \emph{interaction
        topology}.
  \item $\mathcal{R} = \{R_e\}_{e \in E}$ assigns to each edge
        $e = \{s, s'\} \in E$ a \emph{constraint relation}
        $R_e \subseteq D_s \times D_{s'}$.
\end{enumerate}
The \emph{configuration space} is $\Omega = \prod_{s \in S} D_s$, and the
\emph{feasible set} is
$\mathcal{F} = \{\omega \in \Omega \mid \forall e = \{s,s'\} \in E:
(\omega_s, \omega_{s'}) \in R_e\}$.
\end{definition}

\noindent
For the convergence results in \cref{ssec:convergence} and the
coarse-graining construction in \cref{sec:scale-free}, we restrict to
compact Polish state spaces~$D_s$ (hence compact metrizable~$\Omega$)
in order to invoke standard Markov-chain stability results
\citep{meyn1993markov}; the definitions above are stated in greater
generality to clarify which results depend on compactness and which
do not.

\begin{remark}[Finiteness of $S$]\label{rem:finiteness}
The formal development assumes $|S| < \infty$. This suffices for systems
with a natural decomposition into discrete components (particles, neurons,
organisms) but appears to exclude continuum field theories. The physical
examples in \cref{sec:physics} (e.g., fluid parcels in convection) should
be read as finite-element discretizations of the underlying continuum; the
formal extension to countable or measure-theoretic component spaces
(replacing sums with integrals in \cref{eq:violation,eq:coherence}) is
straightforward but introduces technical regularity conditions that we
defer to future work.

We note, however, that the discreteness assumption may be less restrictive
than it appears. The continuity of the optical spectrum, for example, is
not a testable prediction of quantum mechanics---all empirical data is
inherently discrete. \citet{powers2024statistical} demonstrate that a
model built entirely from finite binary sequences reproduces the
probability distributions of canonical quantum mechanics, with small but
unavoidable deviations at finite~$n$ that shrink as $n$ increases.  For
any finite~$n$ the system is a finite constraint network in the sense of
\cref{def:constraint-network}; the continuum of canonical quantum theory
is recovered only in the limit.  This suggests that the continuum
structure of standard physics may be an idealization of a fundamentally
discrete substrate---precisely the kind of substrate that DCR is designed
to describe (see \cref{rem:micro-choices}).
\end{remark}

\begin{definition}[Constraint Violation]\label{def:violation}
The \emph{total constraint violation} of a configuration $\omega \in \Omega$ is
\begin{equation}\label{eq:violation}
  \Viol(\omega) = \sum_{e = \{s,s'\} \in E} v_e(\omega_s, \omega_{s'}),
\end{equation}
where $v_e : D_s \times D_{s'} \to \mathbb{R}_{\geq 0}$ is zero if and only if
$(\omega_s, \omega_{s'}) \in R_e$.
\end{definition}

\subsection{Coherence}\label{ssec:coherence}

We require an information-theoretic measure of how coordinated the components
are.

\begin{definition}[Coherence]\label{def:coherence}
Given a probability distribution $\mu$ over $\Omega$, the \emph{coherence} of
the system is the total correlation (multi-information), defined as the
Kullback--Leibler divergence from the product of marginals:
\begin{equation}\label{eq:coherence}
  \Coh(\mu) = D_{\mathrm{KL}}\!\!\left(\mu \;\Big\|\; \bigotimes_{s \in S} \mu_s\right),
\end{equation}
where $\mu_s$ is the marginal of $\mu$ on $D_s$.  In the discrete case
(or for continuous distributions admitting densities with respect to a
product reference measure), this equals
$\sum_{s \in S} \Ent(\mu_s) - \Ent(\mu)$, where $\Ent$ denotes Shannon
(or differential) entropy.  The KL formulation is preferred because it is
non-negative by construction, invariant under reparametrization, and
well-defined for arbitrary probability measures on Polish spaces.
\end{definition}

Coherence equals zero if and only if the components are statistically
independent under~$\mu$.  High coherence indicates that the components have
resolved into a coordinated pattern: knowing one component's state constrains
the others.

\subsection{The Cognitive Triad}\label{ssec:triad}

\begin{definition}[Exploration]\label{def:exploration}
An \emph{exploration process} on $\mathcal{N}$ is a time-homogeneous
Markov chain $\{X_t\}_{t \geq 0}$ on $\Omega$ with transition
kernel~$K$ that is $\varphi$-irreducible for some measure~$\varphi$
with \emph{full exploration support} on the feasible set:
\[
  \varphi(U) > 0 \quad \text{for every open }
  U \subseteq \Omega \text{ with } U \cap \mathcal{F} \neq \emptyset,
\]
and such that for all $\omega \in \Omega$ and all measurable $A$ with
$\varphi(A) > 0$,
\begin{equation}\label{eq:exploration}
  \sum_{n=1}^{\infty} K^n(\omega, A) > 0.
\end{equation}
Informally: the process can reach any region of configuration space that
intersects the feasible set.  The same measure~$\varphi$ and the same
conditions reappear as \ref{cond:irreducibility} and
\ref{cond:full-support} in the convergence machinery of
\cref{ssec:convergence}.
\end{definition}

\begin{definition}[Distributed Constraint Resolution]\label{def:resolution}
A \emph{resolution dynamics} on $\mathcal{N}$ is a family of local update rules
$\{f_s\}_{s \in S}$ where each $f_s$ depends only on the state of $s$ and its
neighbors $\mathcal{N}_G(s)$ in $G$:
\begin{equation}\label{eq:resolution}
  x_s^{(t+1)} = f_s\!\bigl(x_s^{(t)},\, \{x_{s'}^{(t)}\}_{s' \in \mathcal{N}_G(s)}\bigr),
\end{equation}
such that the total constraint violation is non-increasing in expectation:
\begin{equation}\label{eq:monotone}
  \mathbb{E}\bigl[\Viol(X_{t+1})\bigr] \leq \mathbb{E}\bigl[\Viol(X_t)\bigr].
\end{equation}
The \emph{distributed} qualifier is essential: there is no global objective
function being optimized by a central controller. Constraint satisfaction
emerges from purely local interactions.
\end{definition}

\begin{definition}[Goal-Stabilizing Pattern]\label{def:stabilization}
A \emph{goal-stabilizing pattern} is a subset $\mathcal{A} \subseteq \Omega$
that is:
\begin{enumerate}[nosep]
  \item \emph{Attracting}: The dynamics converges to $\mathcal{A}$, i.e.,
        $d(X_t, \mathcal{A}) \to 0$ as $t \to \infty$ in probability.
  \item \emph{Coherent}: The stationary distribution $\mu^*$ supported on
        $\mathcal{A}$ satisfies $\Coh(\mu^*) > 0$.
  \item \emph{Stable}: There exists a Lyapunov-like function
        $L : \Omega \to \mathbb{R}_{\geq 0}$ that is non-increasing along
        trajectories in a neighborhood of $\mathcal{A}$ and achieves its
        minimum on $\mathcal{A}$.
\end{enumerate}
\end{definition}

We can now state the central definition:

\begin{definition}[Cognitive System]\label{def:cognitive-system}
A \emph{cognitive system} is a tuple
$\mathcal{C} = (\mathcal{N}, \{X_t\}, \{f_s\}, \mathcal{A})$ consisting of a
constraint network $\mathcal{N}$, an exploration process $\{X_t\}$, a
resolution dynamics $\{f_s\}$, and a goal-stabilizing pattern $\mathcal{A}$,
such that the combined dynamics---exploration interleaved with
resolution---converges to $\mathcal{A}$.
\end{definition}

\begin{remark}
The interplay between exploration and resolution is critical. Pure exploration
without resolution yields noise (high entropy, zero coherence). Pure resolution
without exploration yields rigid, brittle structures that cannot adapt. Cognition
requires both: the system must \emph{explore to discover} and
\emph{resolve to stabilize}.
\end{remark}

\subsection{Convergence}\label{ssec:convergence}

We now formalize the combined dynamics precisely and prove convergence through
a sequence of lemmas.

\begin{definition}[Combined DCR Dynamics]\label{def:combined}
Let $\mathcal{N}$ be a constraint network on a compact metrizable configuration
space $\Omega$. A \emph{combined DCR dynamics} is a time-homogeneous Markov
chain $\{X_t\}_{t \geq 0}$ on $\Omega$ with transition kernel
\begin{equation}\label{eq:combined}
  K(\omega, A) = (1 - \epsilon)\, R(\omega, A) + \epsilon\, E(\omega, A),
  \qquad \epsilon \in (0,1),
\end{equation}
where $R$ is the \emph{resolution kernel} (induced by the local update rules
$\{f_s\}$) and $E$ is the \emph{exploration kernel}. We require:
\begin{enumerate}[nosep,label=(\alph*)]
  \item\label{cond:drift} \textbf{Drift.} There exists $\alpha > 0$ such that
    for all $\omega \notin \mathcal{F}$:
    \begin{equation}\label{eq:drift}
      \int_\Omega \Viol(\omega')\, R(\omega, d\omega') \leq
      \Viol(\omega) - \alpha\, \Viol(\omega).
    \end{equation}
  \item\label{cond:bounded-explore} \textbf{Bounded exploration.}
    There exists $B > 0$ such that for all $\omega \in \Omega$:
    \begin{equation}\label{eq:bounded-explore}
      \int_\Omega \Viol(\omega')\, E(\omega, d\omega') \leq B.
    \end{equation}
  \item\label{cond:irreducibility} \textbf{$\varphi$-irreducibility.}
    There exists a probability measure $\varphi$ on $\Omega$ such that for
    all $\omega \in \Omega$ and all measurable $A$ with $\varphi(A) > 0$:
    \begin{equation}\label{eq:irreducibility}
      \sum_{n=1}^{\infty} K^n(\omega, A) > 0.
    \end{equation}
  \item\label{cond:aperiodicity} \textbf{Aperiodicity.}
    For all $\omega \in \Omega$: $K(\omega, \{\omega\}) > 0$, or more
    generally, the chain is strongly aperiodic.
  \item\label{cond:feller} \textbf{Weak Feller property.} For every bounded
    continuous $g : \Omega \to \mathbb{R}$, the map
    $\omega \mapsto \int g(\omega')\, K(\omega, d\omega')$ is continuous.
  \item\label{cond:full-support} \textbf{Full exploration support.} The
    irreducibility measure $\varphi$ satisfies $\varphi(U) > 0$ for every
    open set $U \subseteq \Omega$ with $U \cap \mathcal{F} \neq \emptyset$.
\end{enumerate}
\end{definition}

\begin{lemma}[Foster--Lyapunov Drift Condition]\label{lem:foster}
Under conditions \ref{cond:drift} and \ref{cond:bounded-explore} of
\cref{def:combined}, the function $L(\omega) = \Viol(\omega) + 1$ satisfies
the Foster--Lyapunov drift condition: there exist constants $\lambda \in (0,1)$
and $b < \infty$ such that
\begin{equation}\label{eq:foster}
  \int_\Omega L(\omega')\, K(\omega, d\omega') \leq
  \lambda\, L(\omega) + b\, \mathbf{1}_C(\omega),
\end{equation}
where $C = \{\omega \in \Omega : \Viol(\omega) \leq c\}$ for a suitable
constant $c > 0$.
\end{lemma}

\begin{proof}
Decomposing the transition kernel $K = (1-\epsilon)R + \epsilon E$ and applying
conditions \ref{cond:drift} and \ref{cond:bounded-explore}:
\begin{align}
  \int L(\omega')\, K(\omega,d\omega')
  &= (1-\epsilon) \int \Viol(\omega')\, R(\omega,d\omega')
     + \epsilon \int \Viol(\omega')\, E(\omega,d\omega') + 1 \notag \\
  &\leq (1-\epsilon)(1-\alpha)\,\Viol(\omega) + \epsilon B + 1.
  \label{eq:foster-expand}
\end{align}
Set $\lambda = (1-\epsilon)(1-\alpha)$. Since $\epsilon, \alpha \in (0,1)$,
we have $\lambda \in (0,1)$. Then:
\[
  \int L(\omega')\, K(\omega,d\omega')
  \leq \lambda\bigl(\Viol(\omega) + 1\bigr)
       + (1-\lambda) + \epsilon B
  = \lambda\, L(\omega) + (1 - \lambda + \epsilon B).
\]
For $\omega$ with $\Viol(\omega) > c$ where
$c = (1 - \lambda + \epsilon B) / (1-\lambda)$, the bound becomes
$\lambda\, L(\omega) + (1-\lambda)\, L(\omega) = L(\omega)$ only when equality
holds, but in fact:
\[
  \lambda\, L(\omega) + (1-\lambda+\epsilon B)
  < \lambda\, L(\omega) + (1-\lambda)\, L(\omega) = L(\omega)
\]
whenever $L(\omega) > (1-\lambda+\epsilon B)/(1-\lambda)$, i.e., whenever
$\Viol(\omega) > c$. Setting $b = 1 - \lambda + \epsilon B$ and
$C = \{L(\omega) \leq c + 1\}$ (which is compact since $\Viol$ is continuous
and $\Omega$ is compact), we obtain \cref{eq:foster}.
\end{proof}

\begin{lemma}[Existence of Stationary Distribution]\label{lem:stationary}
Under conditions \ref{cond:drift}--\ref{cond:feller} of \cref{def:combined},
the Markov chain $\{X_t\}$ admits at least one stationary distribution $\mu^*$.
\end{lemma}

\begin{proof}
By \cref{lem:foster}, the chain satisfies a Foster--Lyapunov drift condition
with compact sublevel set $C$. On a compact metrizable space with the weak
Feller property \ref{cond:feller}, the Krylov--Bogoliubov theorem guarantees
the existence of an invariant probability measure: the sequence of Ces\`{a}ro
averages $\mu_T = T^{-1}\sum_{t=0}^{T-1} \Pr[X_t \in \cdot]$ is tight
(the drift condition confines mass to bounded sublevel sets of $L$), and any
weak limit point is a stationary distribution.
\end{proof}

\begin{lemma}[Uniqueness and Ergodicity]\label{lem:unique}
Under conditions \ref{cond:drift}--\ref{cond:feller}, if additionally the
chain is $\varphi$-irreducible \ref{cond:irreducibility} and aperiodic
\ref{cond:aperiodicity}, then the stationary distribution $\mu^*$ is unique,
and for every initial distribution $\mu_0$:
\begin{equation}\label{eq:ergodic}
  \lVert \mu_0 K^t - \mu^* \rVert_{\mathrm{TV}} \to 0
  \quad \text{as } t \to \infty.
\end{equation}
\end{lemma}

\begin{proof}
This follows from the general theory of $\varphi$-irreducible aperiodic Markov
chains on compact state spaces satisfying a Foster--Lyapunov drift condition.
By Theorem~6.1 of Meyn and Tweedie (1993), conditions
\ref{cond:irreducibility}, \ref{cond:aperiodicity}, and \cref{eq:foster}
together imply that the chain is positive Harris recurrent with a unique
stationary distribution, and that the total variation distance to stationarity
converges to zero.
\end{proof}

\begin{lemma}[Concentration Near the Feasible Set]\label{lem:concentration}
For fixed $\epsilon > 0$, the unique stationary distribution
$\mu^*_\epsilon$ (\cref{lem:unique}) satisfies
\begin{equation}\label{eq:concentration}
  \int \Viol(\omega)\, \mu^*_\epsilon(d\omega)
  \leq \frac{\epsilon B}{\alpha(1-\epsilon) + \epsilon}.
\end{equation}
In particular, $\mu^*_\epsilon$ concentrates on an
$O(\epsilon)$-neighborhood of $\mathcal{F}$ as $\epsilon \to 0$.
\end{lemma}

\begin{proof}
Integrating both sides of the stationary equation
$\int \Viol(\omega')\, K(\omega,d\omega')\, \mu^*_\epsilon(d\omega) =
\int \Viol(\omega)\, \mu^*_\epsilon(d\omega)$ and using the drift bound:
\begin{align*}
  \int \Viol(\omega)\, \mu^*_\epsilon(d\omega)
  &= \int\!\!\int \Viol(\omega')\, K(\omega,d\omega')\, \mu^*_\epsilon(d\omega) \\
  &\leq (1-\epsilon)(1-\alpha) \int \Viol(\omega)\, \mu^*_\epsilon(d\omega)
        + \epsilon B.
\end{align*}
Let $m = \int \Viol\, d\mu^*_\epsilon$. Then
$m \leq (1-\epsilon)(1-\alpha)\, m + \epsilon B$, giving
$m\bigl[1 - (1-\epsilon)(1-\alpha)\bigr] \leq \epsilon B$, hence
\cref{eq:concentration}. Since $\Viol \geq 0$ with equality exactly on
$\mathcal{F}$, the expected violation under $\mu^*_\epsilon$ vanishes as
$\epsilon \to 0$, so $\mu^*_\epsilon$ concentrates on $\mathcal{F}$.
\end{proof}

\begin{lemma}[Convergence Under Cooling]\label{lem:cooling}
Replace the fixed $\epsilon$ in \cref{def:combined} with a cooling schedule
$\epsilon_t \to 0$. If $\epsilon_t$ decreases no faster than $O(1/\log t)$
(i.e., $\epsilon_t \geq c/\log(t+2)$ for some $c > 0$), then the occupation
measures $\mu_T = T^{-1} \sum_{t=0}^{T-1} \delta_{X_t}$ converge weakly to
a distribution $\mu^*$ supported on the set of global minima of $\Viol$,
which is precisely $\mathcal{F}$.
\end{lemma}

\begin{proof}
The cooling schedule produces an inhomogeneous Markov chain to which the
homogeneous results of \cref{lem:unique} do not directly apply. Instead, we
appeal to the simulated annealing theory of \citet{hajek1988cooling}. The
resolution kernel $R$ plays the role of the annealing kernel (it decreases
the objective $\Viol$ by the drift condition~\ref{cond:drift}), and the
exploration kernel $E$ provides the proposal mechanism. Hajek's conditions
require: (i)~the chain under $E$ is irreducible---guaranteed by our
condition~\ref{cond:irreducibility}; (ii)~$\Viol$ has a finite number of
local minima connected by paths of bounded ``depth'' (height of the
shallowest saddle)---guaranteed by compactness of $\Omega$ and continuity
of $\Viol$; and (iii)~$\epsilon_t$ decreases as $c/\log(t+2)$ with
$c$ exceeding the maximum depth. Under these conditions, convergence to
$\mathcal{F}$ (the global minimizers of $\Viol$) is guaranteed.
\end{proof}

\begin{lemma}[Positive Coherence]\label{lem:coherence}
Let $\mu^*$ be a distribution supported on the feasible set $\mathcal{F}$.
Suppose:
\begin{enumerate}[nosep,label=(\roman*)]
  \item The constraint graph $G$ is connected.
  \item $\mathcal{F}$ does not factor as a Cartesian product, i.e., there is
    no decomposition $\mathcal{F} = \prod_{s \in S} F_s$ with
    $F_s \subseteq D_s$.
  \item $\mathrm{supp}(\mu^*) = \mathcal{F}$ (full support on the feasible
    set).
\end{enumerate}
Then $\Coh(\mu^*) > 0$.
\end{lemma}

\begin{proof}
By \cref{def:coherence}, $\Coh(\mu) = D_{\mathrm{KL}}(\mu \,\|\,
\bigotimes_{s \in S} \mu_s)$.  This divergence equals zero if and only if
$\mu = \bigotimes_s \mu_s$, i.e., the components are jointly independent
under $\mu$.

Suppose for contradiction that $\Coh(\mu^*) = 0$. Then
$\mu^* = \bigotimes_s \mu^*_s$. By assumption~(iii),
$\mathrm{supp}(\mu^*) = \mathcal{F}$, so
$\mathrm{supp}(\bigotimes_s \mu^*_s) = \prod_s \mathrm{supp}(\mu^*_s)
= \mathcal{F}$.
This means $\mathcal{F}$ factors as $\prod_s F_s$ with
$F_s = \mathrm{supp}(\mu^*_s) \subseteq D_s$, contradicting
assumption~(ii). Hence $\Coh(\mu^*) > 0$.

It remains to verify that assumption~(iii) holds for the stationary
distributions arising from DCR dynamics. Under the full exploration support
condition~\ref{cond:full-support}, the irreducibility measure $\varphi$
charges every open set meeting $\mathcal{F}$. For the fixed-$\epsilon$ chain,
$\mu^*_\epsilon$ is equivalent to $\varphi$ on the Harris-recurrent set
(Theorem~10.4.9 of \citealp{meyn1993markov}), so
$\mathrm{supp}(\mu^*_\epsilon) \supseteq \mathcal{F}$. Combined with the
concentration bound of \cref{lem:concentration}, the limiting distribution
$\mu^*$ (obtained via cooling or taking $\epsilon \to 0$) has
$\mathrm{supp}(\mu^*) = \mathcal{F}$.
\end{proof}

We can now state and prove the main convergence theorem:

\begin{theorem}[Convergence of DCR Dynamics]\label{thm:convergence}
Let $\mathcal{N}$ be a constraint network with compact configuration space
$\Omega$ and non-empty feasible set $\mathcal{F}$ that does not factor as a
product. Let the constraint graph $G$ be connected.

\textbf{(A) Fixed exploration.}
Let $\{X_t\}$ be a combined DCR dynamics (\cref{def:combined}) with fixed
$\epsilon \in (0,1)$ satisfying conditions
\ref{cond:drift}--\ref{cond:full-support}. Then the chain converges to a
unique stationary distribution $\mu^*_\epsilon$ with
$\int \Viol\, d\mu^*_\epsilon \leq \epsilon B / [\alpha(1-\epsilon)+\epsilon]$
and $\Coh(\mu^*_\epsilon) > 0$.

\textbf{(B) Cooling schedule.}
Replace the fixed $\epsilon$ with a cooling schedule
$\epsilon_t = c / \log(t+2)$ for suitable $c > 0$. Then the occupation
measures converge to $\mu^*$ supported on $\mathcal{F}$, with
$\Coh(\mu^*) > 0$, and $\mathcal{F}$ is a goal-stabilizing pattern with
Lyapunov function $L = \Viol + 1$.
\end{theorem}

\begin{proof}
\textbf{Part~(A).}
By \cref{lem:foster}, the chain satisfies a Foster--Lyapunov drift condition.
By \cref{lem:stationary}, a stationary distribution $\mu^*_\epsilon$ exists.
By \cref{lem:unique}, $\mu^*_\epsilon$ is unique and the chain is ergodic.
By \cref{lem:concentration}, $\mu^*_\epsilon$ satisfies the stated violation
bound. By condition~\ref{cond:full-support} and Harris recurrence,
$\mathrm{supp}(\mu^*_\epsilon) \supseteq \mathcal{F}$. Since $\mathcal{F}$
does not factor and $G$ is connected, \cref{lem:coherence} gives
$\Coh(\mu^*_\epsilon) > 0$.

\textbf{Part~(B).}
The cooling schedule produces an inhomogeneous chain. By \cref{lem:cooling}
(applying \citealp{hajek1988cooling}), the occupation measures converge to
$\mu^*$ supported on $\mathcal{F}$. For coherence: the chain is
irreducible on $\mathcal{F}$ by condition~\ref{cond:full-support} (every
open subset of $\mathcal{F}$ is reachable), so the chain visits all
regions of $\mathcal{F}$ infinitely often, giving
$\mathrm{supp}(\mu^*) = \mathcal{F}$. Since $G$ is connected and
$\mathcal{F}$ does not factor, $\Coh(\mu^*) > 0$ by
\cref{lem:coherence}.

Finally, $L(\omega) = \Viol(\omega) + 1$ achieves its minimum value~$1$ on
$\mathcal{F}$, is continuous and bounded on compact $\Omega$, and is strictly
decreasing in expectation outside $\mathcal{F}$ by condition~\ref{cond:drift}.
This establishes $\mathcal{F}$ as a goal-stabilizing pattern.
\end{proof}

\subsection{What DCR Excludes}\label{ssec:exclusions}

A definition of cognition is only useful if it excludes something. DCR excludes
three classes of systems:

\begin{enumerate}
  \item \textbf{Equilibrium systems.} A system at thermodynamic equilibrium
        occupies a maximum-entropy state with no net flows. There is no
        exploration (all degrees of freedom are maximally sampled but with no
        directed dynamics) and no resolution (constraints are already trivially
        satisfied or absent). $\Coh(\mu_{\text{eq}}) = 0$ for an ideal gas.
        \emph{A rock at thermal equilibrium is not cognitive.}

  \item \textbf{Unconstrained stochastic systems.} A system with exploration
        but no constraint structure ($\mathcal{R} = \emptyset$) undergoes a
        random walk on $\Omega$ with no convergence to coherent patterns.
        $\Viol \equiv 0$ trivially, and $\Coh(\mu) = 0$ for the stationary
        (uniform) distribution. \emph{Brownian motion in free space is not
        cognitive.}

  \item \textbf{Fully deterministic single-trajectory systems.} A system with
        a single degree of freedom following a deterministic trajectory has no
        exploration (the path is unique) and no distributed resolution (there
        is only one component). \emph{A single classical particle in a
        potential well is not cognitive.}
\end{enumerate}

Cognition in the DCR sense requires the non-trivial intersection:
non-equilibrium dynamics, constraint structure, and distributed convergence
to coherent attractors.

We emphasize that the boundary between cognitive and non-cognitive is
\emph{continuous}, not sharp. A system near equilibrium with weak
constraints and small fluctuations satisfies the DCR conditions only
marginally: the coherence $\Coh(\mu^*)$ is near zero and the convergence
timescale is long. DCR does not impose a binary threshold; rather, it
provides a graded measure through the coherence of the attractor and the
cognitive depth $\delta$ (\cref{def:depth}). The exclusions above identify
the \emph{limiting cases} where one or more components of the triad vanish
entirely, not a boundary that systems cross discontinuously.

% ==========================================================================
\section{Scale-Freeness and the Combination Problem}\label{sec:scale-free}
% ==========================================================================

The central mathematical contribution of this paper is showing that DCR is
closed under coarse-graining: cognitive systems at one scale compose into
cognitive systems at the next, providing a formal dissolution of the
combination problem.

The closure result (\cref{thm:closure}) requires \emph{timescale separation}
between intra-group and inter-group dynamics---a condition that holds in many
physical systems (atomic vs.\ molecular, synaptic vs.\ network) but is not
universal. We regard this as a sufficient condition, not a necessary one;
weakening it to overlapping timescales or continuous-time limits is an
important open problem (see \cref{sec:discussion}). The framework's axioms
(\cref{sec:framework}) are themselves scale-free; it is specifically the
composition mechanism that requires separation.

\subsection{The Coarse-Graining Construction}\label{ssec:coarse-graining}

\begin{definition}[Coarse-Graining]\label{def:coarse-graining}
Let $\mathcal{C} = (\mathcal{N}, \{X_t\}, \{f_s\}, \mathcal{A})$ be a
cognitive system with component set $S$, and let
$\pi : S \twoheadrightarrow S'$ be a surjective \emph{partition map}
grouping components into macro-components. A \emph{coarse-graining}
$\Gamma_{\pi,g}(\mathcal{C})$ additionally requires \emph{compression
maps} $\{g_{s'}\}_{s' \in S'}$ and is constructed as follows:

\begin{enumerate}[nosep]
  \item \textbf{Compression maps:} For each $s' \in S'$, a measurable
        surjection $g_{s'} : \prod_{s \in \pi^{-1}(s')} D_s \to
        \tilde{D}_{s'}$ onto a measurable \emph{macro-state space}
        $\tilde{D}_{s'}$, typically of lower dimension than the group
        state space $\prod_{s \in \pi^{-1}(s')} D_s$. The global
        compression
        $g : \Omega \to \tilde{\Omega} = \prod_{s'} \tilde{D}_{s'}$ is
        defined by $g(\omega)_{s'} = g_{s'}(\omega_{\pi^{-1}(s')})$.
  \item \textbf{Macro-components:} $S' = \pi(S)$, with state spaces
        $\tilde{D}_{s'}$.
  \item \textbf{Macro-constraints:} An edge $\{s'_1, s'_2\} \in E'$ exists
        whenever there exist $s_1 \in \pi^{-1}(s'_1)$ and
        $s_2 \in \pi^{-1}(s'_2)$ with $\{s_1, s_2\} \in E$. The
        macro-constraint
        $\tilde{R}_{\{s'_1,s'_2\}} \subseteq \tilde{D}_{s'_1} \times
        \tilde{D}_{s'_2}$ consists of all macro-state pairs
        $(\tilde{\omega}_{s'_1}, \tilde{\omega}_{s'_2})$ for which there
        exist group configurations in the preimages
        $g_{s'_j}^{-1}(\tilde{\omega}_{s'_j})$ satisfying all cross-group
        micro-constraints between $\pi^{-1}(s'_1)$ and $\pi^{-1}(s'_2)$.
        Once the macro-violation $\tilde{v}_{e'}$ is available
        (\cref{def:macro-violation}), the effective macro-constraint is
        its zero set:
        $\tilde{R}_{\{s'_1,s'_2\}} = \{(\tilde{\omega}_{s'_1},
        \tilde{\omega}_{s'_2}) :
        \tilde{v}_{\{s'_1,s'_2\}}(\tilde{\omega}_{s'_1},
        \tilde{\omega}_{s'_2}) = 0\}$; the existential definition above
        serves only to establish the edge set $E'$.
  \item \textbf{Macro-dynamics:} The compressed process
        $\{\tilde{X}_t\}$ on $\tilde{\Omega}$ is given by
        $\tilde{X}_t = g(X_t)$.
  \item \textbf{Macro-attractor:}
        $\tilde{\mathcal{A}} = g(\mathcal{A})$.
\end{enumerate}
Whenever any $g_{s'}$ is non-injective---the generic and intended
case---the compression discards degrees of freedom: $\tilde{\Omega}$
carries strictly less information than $\Omega$ (and in
Euclidean-state cases, has lower dimension). Concrete choices of
$g_{s'}$ include empirical averages (mean-field), order parameters,
sufficient statistics, or information-bottleneck summaries; the
appropriate choice is determined by the physics of the system and the
timescale separation structure (\cref{def:timescale}).

We assume throughout that all state spaces $D_s$ (and hence
$\tilde{D}_{s'}$) are Polish (complete separable metrizable) and that
all maps and constraint relations are Borel. Under these standing
assumptions, images and projections of Borel sets are analytic and
hence universally measurable. In particular,
$\tilde{\mathcal{R}}$, $\tilde{\mathcal{F}}$, and the pushforward
measures arising in the construction are universally measurable
(though not Borel in general).
\end{definition}

We now state the conditions precisely and prove closure through three lemmas,
one for each component of the cognitive triad.

\begin{definition}[Timescale Separation]\label{def:timescale}
Let $\eta > 0$ be a \emph{scale ratio}. We say the micro-dynamics exhibits
$\eta$-\emph{timescale separation} with respect to partition $\pi$ and
compression $\{g_{s'}\}$ if:
\begin{enumerate}[nosep]
  \item \textbf{Fast intra-group mixing.} For each macro-component
    $s' \in S'$, let $\partial s'$ denote the micro-components outside
    $\pi^{-1}(s')$ that share an edge with some component inside
    $\pi^{-1}(s')$ (the \emph{micro-boundary} of group $s'$). For each
    boundary configuration $b_{s'} = (\omega_s)_{s \in \partial s'}$,
    the restricted chain on $\prod_{s \in \pi^{-1}(s')} D_s$ with
    $b_{s'}$ frozen has a unique conditional equilibrium
    $\nu_{s'}(\cdot \mid b_{s'})$ and mixes to this equilibrium in time
    $\tau_{\text{fast}}$.
  \item \textbf{Slow inter-group dynamics.} The inter-group updates (those
    involving edges in $E_{\text{cross}} = \{\{s_1,s_2\} \in E \mid
    \pi(s_1) \neq \pi(s_2)\}$) occur at rate $\eta$ relative to intra-group
    updates.
  \item $\eta\, \tau_{\text{fast}} \to 0$, i.e., fast degrees of freedom
    equilibrate before the next inter-group update.
  \item \textbf{Macro-sufficiency (representative-independence).}
    Define the \emph{macro-boundary} of group $s'$ as
    $\tilde{b}_{s'}(\tilde{\omega}) =
    (\tilde{\omega}_{s''})_{s'' \in \mathcal{N}_{G'}(s')}$.
    For each global micro-configuration $\omega \in \Omega$ write
    $b_{s'}(\omega) := (\omega_s)_{s \in \partial s'}$ for the induced
    micro-boundary.  We require that for any two micro-configurations
    $\omega, \omega' \in \Omega$ and any inter-group edge
    $\{s_1, s_2\} \in E_{\text{cross}}$ with $\pi(s_j) = s'_j$,
    if $\tilde{b}_{s'_1}(g(\omega)) = \tilde{b}_{s'_1}(g(\omega'))$
    and
    $\tilde{b}_{s'_2}(g(\omega)) = \tilde{b}_{s'_2}(g(\omega'))$,
    then
    \[
      \mathbb{E}_{\nu_{s'_1}(\cdot \mid b_{s'_1}(\omega)) \otimes
      \nu_{s'_2}(\cdot \mid b_{s'_2}(\omega))}
      \bigl[v_{\{s_1,s_2\}}\bigr]
      =
      \mathbb{E}_{\nu_{s'_1}(\cdot \mid b_{s'_1}(\omega')) \otimes
      \nu_{s'_2}(\cdot \mid b_{s'_2}(\omega'))}
      \bigl[v_{\{s_1,s_2\}}\bigr].
    \]
\end{enumerate}
Condition~4 says that the compression maps capture all boundary
information relevant to inter-group interactions: two global
micro-configurations that agree on the macro-neighborhood of both
endpoint groups yield the same expected cross-group violation after
fast equilibration, even if their micro-boundaries differ in detail
not captured by $g$.
This is what makes $\tilde{v}_{e'}$ in \cref{def:macro-violation}
well-defined as a function on $\tilde{D}_{s'_1} \times
\tilde{D}_{s'_2}$.  We take macro-sufficiency as a sufficient
condition ensuring well-defined macro-violations; weaker approximate
forms (e.g., $\epsilon$-lumpability, where the displayed equality holds
up to an error of order~$\epsilon$) are natural relaxations that we
leave to future work.
\end{definition}

\begin{definition}[Macro-Violation]\label{def:macro-violation}
Given the conditional equilibria from \cref{def:timescale}, the
\emph{macro-violation} of a macro-configuration
$\tilde{\omega} = (\tilde{\omega}_{s'})_{s' \in S'} \in \tilde{\Omega}$
with respect to an inter-group edge $e' = \{s'_1, s'_2\} \in E'$ is
\begin{equation}\label{eq:macro-violation}
  \tilde{v}_{e'}(\tilde{\omega}_{s'_1}, \tilde{\omega}_{s'_2}) =
  \sum_{\substack{\{s_1,s_2\} \in E_{\text{cross}} \\
  \pi(s_1) = s'_1,\, \pi(s_2) = s'_2}}
  \mathbb{E}_{\nu_{s'_1}(\cdot\,|\,b_{s'_1}) \otimes
  \nu_{s'_2}(\cdot\,|\,b_{s'_2})}
  \bigl[v_{\{s_1,s_2\}}(x_{s_1}, x_{s_2})\bigr],
\end{equation}
where $\omega \in \Omega$ is any micro-configuration satisfying
$g(\omega) = \tilde{\omega}$ and $b_{s'_j} = b_{s'_j}(\omega)$ denotes
the induced micro-boundary of group~$s'_j$.
The total macro-violation is
$\widetilde{\Viol}(\tilde{\omega}) = \sum_{e' \in E'}
\tilde{v}_{e'}$. By the representative-independence condition
(\cref{def:timescale}, item~4), the right-hand side of
\cref{eq:macro-violation} does not depend on the choice of~$\omega$,
so $\tilde{v}_{e'}$ is well-defined as a function on
$\tilde{D}_{s'_1} \times \tilde{D}_{s'_2}$.
\end{definition}

\begin{lemma}[Macro-Resolution Inherits Drift]\label{lem:macro-drift}
Under $\eta$-timescale separation (\cref{def:timescale}), if the
micro-resolution dynamics satisfies the drift condition \ref{cond:drift} of
\cref{def:combined} with parameter $\alpha$, then the effective
macro-dynamics on $\tilde{\Omega}$ satisfies an analogous drift condition
for $\widetilde{\Viol}$ with parameter $\alpha' > 0$.
\end{lemma}

\begin{proof}
Decompose the total micro-violation into intra-group and inter-group parts:
$\Viol(\omega) = \Viol_{\text{intra}}(\omega) + \Viol_{\text{inter}}(\omega)$.
Under timescale separation, the fast dynamics drives
$\Viol_{\text{intra}} \to 0$ within each group (by the micro-level drift
condition applied to intra-group edges). Once each group has equilibrated to
$\nu_{s'}(\cdot \mid b_{s'})$, the remaining violation is purely
inter-group: $\Viol \approx \Viol_{\text{inter}}$. By
macro-sufficiency, $\Viol_{\text{inter}}$ under local equilibrium
depends on the micro-boundary only through the macro-boundary
$\tilde{b}_{s'}$, and hence through the macro-state
$\tilde{\omega} = g(\omega)$, so
$\mathbb{E}[\Viol_{\text{inter}} \mid \text{local eq.}]
= \widetilde{\Viol}(\tilde{\omega})$.

The inter-group updates are local: an update to component $s_1 \in
\pi^{-1}(s'_1)$ responding to the state of $s_2 \in \pi^{-1}(s'_2)$ reduces
$v_{\{s_1,s_2\}}$ by the micro-drift condition. Under equilibration within
each group, this translates to a reduction in
$\tilde{v}_{\{s'_1,s'_2\}}$.

Formally, let $\tilde{\omega}_t$ denote the macro-state at the $t$-th
inter-group update. Conditioning on the intra-group equilibrium:
\begin{align*}
  \mathbb{E}[\widetilde{\Viol}(\tilde{\omega}_{t+1}) \mid \tilde{\omega}_t]
  &= \sum_{e' \in E'}
     \mathbb{E}[\tilde{v}_{e'}(\tilde{\omega}_{t+1}) \mid \tilde{\omega}_t] \\
  &\leq \sum_{e' \in E'} (1 - \alpha)\,
     \tilde{v}_{e'}(\tilde{\omega}_t)
   + O(\eta\, \tau_{\text{fast}}) \\
  &= (1-\alpha)\, \widetilde{\Viol}(\tilde{\omega}_t)
   + O(\eta\, \tau_{\text{fast}}).
\end{align*}
The error term $O(\eta\, \tau_{\text{fast}})$ vanishes as the timescale
separation strengthens, yielding the macro-drift condition with
$\alpha' = \alpha - O(\eta\, \tau_{\text{fast}}) > 0$ for sufficiently
strong separation.
\end{proof}

\begin{lemma}[Macro-Exploration Inherits Accessibility]\label{lem:macro-explore}
If the micro-exploration kernel $E$ satisfies the accessibility condition
(\cref{eq:exploration}) with respect to the micro-feasible set, $g$ is
continuous and surjective, and the partition $\pi$ is finite, then the
compressed macro-process $\{\tilde{X}_t = g(X_t)\}$ satisfies the
accessibility condition with respect to the macro-feasible set
$\tilde{\mathcal{F}} = g(\mathcal{F})$.
\end{lemma}

\begin{proof}
Let $\tilde{A} \subseteq \tilde{\Omega}$ be a measurable set with
$\tilde{\varphi}(\tilde{A}) > 0$, where $\tilde{\varphi}$ is the
pushforward of $\varphi$ under $g$. Define
$A = g^{-1}(\tilde{A}) \subseteq \Omega$. Since $g$ is surjective,
$\varphi(A) \geq \tilde{\varphi}(\tilde{A}) > 0$, so by
micro-accessibility:
\[
  \Pr[\exists\, t > 0 : X_t \in A] > 0.
\]
Since $\tilde{X}_t = g(X_t)$, if $X_t \in A = g^{-1}(\tilde{A})$ then
$\tilde{X}_t \in \tilde{A}$. Therefore
$\Pr[\exists\, t > 0 : \tilde{X}_t \in \tilde{A}] > 0$,
establishing macro-accessibility.
\end{proof}

\begin{lemma}[Macro-Coherence]\label{lem:macro-coherence}
If the macro-constraint graph $G'$ is connected, the macro-feasible set
$\tilde{\mathcal{F}} = g(\mathcal{F})$ does not factor as a product
$\prod_{s'} \tilde{F}_{s'}$, and the macro-system satisfies the full
exploration support condition~\ref{cond:full-support} on $\tilde{\Omega}$,
then any stationary distribution $\tilde{\mu}^*$ arising from the
macro-DCR dynamics satisfies $\Coh(\tilde{\mu}^*) > 0$.
\end{lemma}

\begin{proof}
This is a direct application of \cref{lem:coherence} to the macro-system
on $\tilde{\Omega}$. The macro-system has the same formal structure
(constraint network with connected graph, non-factorable feasible set),
and full exploration support on $\tilde{\mathcal{F}}$ guarantees the
full-support assumption~(iii) of \cref{lem:coherence}.
\end{proof}

\begin{theorem}[Closure Under Coarse-Graining]\label{thm:closure}
Let $\mathcal{C}$ be a cognitive system, $\pi : S \twoheadrightarrow S'$
a partition map, and $\{g_{s'}\}$ compression maps with continuous,
surjective $g : \Omega \to \tilde{\Omega}$. If:
\begin{enumerate}[nosep]
  \item[(i)] The micro-dynamics exhibits $\eta$-timescale separation with
    respect to $\pi$ and $\{g_{s'}\}$ (\cref{def:timescale}).
  \item[(ii)] The macro-constraint graph $G'$ is connected.
  \item[(iii)] The macro-feasible set $\tilde{\mathcal{F}} = g(\mathcal{F})$
    is non-empty, compact, and does not factor as a product.
\end{enumerate}
Then $\tilde{\mathcal{C}} = \Gamma_{\pi,g}(\mathcal{C})$ is a cognitive
system on the compressed macro-state space $\tilde{\Omega}$.
\end{theorem}

\begin{proof}
We verify each component of \cref{def:cognitive-system} for
$\tilde{\mathcal{C}}$:

\textbf{Constraint network.}
The macro-network
$\tilde{\mathcal{N}} = (S', \tilde{\mathcal{D}}, G', \tilde{\mathcal{R}})$
is well-defined by the construction in \cref{def:coarse-graining}. The
macro-state spaces $\tilde{D}_{s'}$ are images of compact sets under
continuous maps (hence compact). The macro-constraints
$\tilde{\mathcal{R}}$ are images of micro-constraints under the
compression (hence universally measurable, as in
\cref{def:coarse-graining}).

\textbf{Exploration.}
By \cref{lem:macro-explore}, the compressed process
$\{\tilde{X}_t = g(X_t)\}$ satisfies the accessibility condition on
$\tilde{\Omega}$. The aperiodicity of the micro-chain projects through
continuous $g$ to aperiodicity of the macro-chain. The weak Feller
property is preserved under continuous surjections ($g$ maps compact
$\Omega$ to compact $\tilde{\Omega}$). Full exploration
support~\ref{cond:full-support} lifts: if
$\tilde{U} \subseteq \tilde{\Omega}$ is open with
$\tilde{U} \cap \tilde{\mathcal{F}} \neq \emptyset$, then
$g^{-1}(\tilde{U})$ is open in $\Omega$ and meets $\mathcal{F}$
(since $g(\mathcal{F}) = \tilde{\mathcal{F}}$), so
$\varphi(g^{-1}(\tilde{U})) > 0$, giving
$\tilde{\varphi}(\tilde{U}) > 0$.

\textbf{Resolution.}
By \cref{lem:macro-drift}, the effective macro-dynamics satisfies a drift
condition on $\tilde{\Omega}$ with parameter $\alpha' > 0$, and the
updates are local with respect to $G'$ (they depend only on the
macro-states of neighboring macro-components, by macro-sufficiency).

\textbf{Goal-stabilizing pattern.}
Applying \cref{thm:convergence} to the macro-system on $\tilde{\Omega}$
(whose conditions are verified above): the macro-dynamics converges to a
stationary distribution $\tilde{\mu}^*$ supported on
$\tilde{\mathcal{F}}$ (by the macro-drift condition and compactness).
By \cref{lem:macro-coherence} and conditions (ii)--(iii),
$\Coh(\tilde{\mu}^*) > 0$. The Lyapunov function is
$\tilde{L}(\tilde{\omega}) = \widetilde{\Viol}(\tilde{\omega}) + 1$.

Hence all four components of a cognitive system are present, and
$\tilde{\mathcal{C}}$ is cognitive.
\end{proof}

\subsection{Dissolution of the Combination Problem}\label{ssec:combination}

The combination problem in panpsychism asks: if fundamental entities have
experience, how do micro-experiences combine into the unified macro-experience
of, say, a human mind? DCR dissolves this problem by replacing the notion of
``combining experiences'' with a formal construction:

\begin{corollary}[Combination via Coarse-Graining]\label{cor:combination}
Let $\mathcal{C}$ be a cognitive system at scale $n$ with partition $\pi$
and compression $\{g_{s'}\}$ satisfying the conditions of
\cref{thm:closure}. Then:
\begin{enumerate}[nosep]
  \item The intra-group cognitive dynamics at scale $n$ (exploration and
        resolution within each $\pi^{-1}(s')$) constitutes the
        \emph{exploration component} of the scale-$(n+1)$ system---the
        residual fluctuations of equilibrated groups, projected through
        $g_{s'}$ onto the macro-state space, provide the stochasticity
        that drives macro-exploration (\cref{lem:macro-explore}).
  \item The inter-group constraint resolution at scale $n$ constitutes the
        \emph{resolution component} of the scale-$(n+1)$ system---the
        reduction of macro-violation (\cref{lem:macro-drift}).
  \item The macro-attractor $\tilde{\mathcal{A}} = g(\mathcal{A})$ is the
        coherent pattern into which the micro-cognitive processes compose
        (\cref{lem:macro-coherence}).
\end{enumerate}
\end{corollary}

\begin{proof}
Each claim follows directly from the corresponding lemma used in the proof
of \cref{thm:closure}. The key observation is structural: the compression
maps $\{g_{s'}\}$ discard the fast, intra-group micro-detail (which has
already been resolved at scale $n$) and retain only the slow
macro-observables. The coarse-graining construction maps the resolution of
scale $n$ to the exploration of scale $n+1$ because once intra-group
constraints are resolved (fast timescale), the residual fluctuations
\emph{in the compressed representation} are precisely what the macro-level
``explores.'' The construction does not merely aggregate states---it
\emph{compresses and transmutes} one level's resolution into the next
level's exploration, providing a constructive mechanism for cross-scale
composition that genuinely reduces degrees of freedom.
\end{proof}

There is no mystery of ``combination'' because there is no separate substance
(experience, qualia) that needs combining. There is only the DCR process,
recurring at each scale via coarse-graining. The compression maps formalize
how micro-detail is discarded at each level: a neuron's molecular state is
compressed to its firing rate; a population's firing rates are compressed to
a mean-field activation; a cortical column's activations are compressed to a
feature representation. What we call ``unified experience'' at the human
scale is the coherent attractor of a cognitive system whose components are
themselves compressed cognitive systems, recursively.

The \emph{micro-choices} framing (\cref{rem:micro-choices}) sharpens this
point.  What is fundamental at each scale is not ``micro-experience'' or
``micro-qualia'' but \emph{micro-degrees of freedom}---hidden variables,
internal microstates, symbol orderings---whose structured resolution under
constraints produces the exploration noise that the next scale up
inherits.  Coarse-graining turns micro-choice variability into
macro-level exploration (\cref{cor:combination}, item~1): the residual
fluctuations of equilibrated groups, projected through the compression
maps, are precisely the stochastic input that drives macro-level
constraint resolution.  This avoids the ``combination of qualia'' trap
entirely: there are no qualia to combine, only degrees of freedom to
compress.

\subsection{The Depth of Cognition}\label{ssec:depth}

Not all cognitive systems are equally ``intelligent.'' We introduce a measure
of cognitive depth:

\begin{definition}[Cognitive Depth]\label{def:depth}
The \emph{cognitive depth} of a system is the number of nested
coarse-graining levels $k$ at which the DCR triad is simultaneously active:
\begin{equation}\label{eq:depth}
  \delta(\mathcal{C}) = \max\{k \mid \Gamma_{\pi_k,g_k} \circ \cdots \circ
  \Gamma_{\pi_1,g_1}(\mathcal{C}) \text{ is cognitive}\},
\end{equation}
where the maximum is over all hierarchical sequences of partitions
$(\pi_1, \ldots, \pi_k)$ and compression maps $(g_1, \ldots, g_k)$
satisfying the conditions of \cref{thm:closure} at each level.
\end{definition}

A hydrogen atom has depth 1 (quantum constraint resolution at the particle
level). A bacterium has depth $\sim$3--4 (molecular, metabolic, behavioral).
A human brain has depth $\sim$6--8 (ionic, synaptic, columnar, areal, network,
behavioral, social). This provides a qualitative, non-anthropocentric
ordering of intelligence without requiring a binary threshold.

\begin{remark}[Computability of depth]\label{rem:depth-computability}
Computing $\delta(\mathcal{C})$ exactly requires optimizing over all
hierarchical partition sequences $(\pi_1, \ldots, \pi_k)$ and compression
maps $(g_1, \ldots, g_k)$, verifying the DCR conditions at each
level---a combinatorially intractable problem in general. The numerical estimates above are based on \emph{empirically
observable} organizational levels (e.g., the well-established hierarchy from
ion channels to brain areas) rather than exhaustive search. In practice,
$\delta$ serves as a coarse ordinal ranking rather than a precise cardinal
measure: distinguishing depth~2 from depth~6 is meaningful; distinguishing
depth~6 from depth~7 requires detailed empirical verification of the DCR
triad at each level.
\end{remark}

% ==========================================================================
\section{Physics as Cognition}\label{sec:physics}
% ==========================================================================

We now demonstrate that fundamental physical processes satisfy the DCR axioms,
supporting the claim that the cosmos is cognitive at every scale.

\subsection{Quantum Mechanics}\label{ssec:quantum}

Consider a system of $N$ interacting quantum particles (or field modes).
The standard decoherence account \citep{zurek2003decoherence} treats
the suppression of off-diagonal coherences as the mechanism by which
classical reality emerges, but decoherence alone never yields a definite
outcome---it produces an improper mixture, not a selected event. The DCR
structure of quantum mechanics is most transparently exhibited by the
\emph{Transactional Interpretation} (TIQM)
\citep{cramer1986transactional}, which builds on the Wheeler--Feynman
absorber theory \citep{wheeler1945interaction}. In TIQM, every quantum
event is a \emph{transaction}---a completed handshake between emitter and
absorber mediated by retarded (offer) and advanced (confirmation) waves.
We use TIQM as a \emph{structural witness} that quantum dynamics can be
read as a distributed constraint-resolution process; DCR does not require
endorsing any particular interpretation of quantum mechanics.  The mapping
onto the DCR triad is as follows:

\begin{itemize}[nosep]
  \item \textbf{Components:} Emitter and absorber sites---the vertices of
        the spacetime interaction graph.
  \item \textbf{Degrees of freedom:} The possible quantum states (energy,
        momentum, polarization, spin) at each site, drawn from the local
        Hilbert space $\mathcal{H}_s$.
  \item \textbf{Exploration:} The \emph{offer wave} $\psi$ (retarded wave)
        propagates from the emitter to all potential absorbers, exploring
        every possible transaction partner simultaneously. In the Feynman
        path integral formulation \citep{feynman1948space}, this is the sum
        over all paths weighted by $e^{iS/\hbar}$---the emitter explores the
        entire accessible configuration space.
  \item \textbf{Constraints:} Conservation laws (energy, momentum, angular
        momentum, charge) at each interaction vertex. For an edge
        $\{s,s'\}$ in the interaction graph, the constraint $R_{\{s,s'\}}$
        requires that the quantum numbers carried by the offer wave from
        emitter $s$ match those that absorber $s'$ can accept, given $s'$'s
        own state and the applicable conservation laws.
  \item \textbf{Resolution:} The \emph{confirmation wave} $\psi^*$ (advanced
        wave) propagates from each potential absorber back to the emitter.
        The Wheeler--Feynman handshake is distributed constraint resolution:
        each absorber independently evaluates the offer against its local
        constraints and responds; the transaction that forms is the one
        where all constraints are simultaneously satisfied across both
        endpoints. There is no central selector choosing the outcome---the
        definite result emerges from the mutual satisfaction of local
        conservation laws, distributed across spacetime.
  \item \textbf{Stable pattern:} The \emph{completed transaction}---a
        definite, irreversible transfer of conserved quantities between
        emitter and absorber. Once formed, the transaction is a classical
        fact: the goal-stabilizing attractor of the handshake process.
\end{itemize}

The retrocausal structure is not a defect but a feature: constraints
propagate both forward and backward in time, making the resolution
genuinely distributed across spacetime rather than confined to a single
time-slice. What is conventionally called ``wavefunction collapse'' is,
in DCR terms, the convergence of a distributed constraint satisfaction
process to its feasible solution.

For $N$ interacting particles, the interaction graph $G$ has particles as
vertices and pairwise interactions as edges. Each interaction is a
potential transaction site where conservation constraints must be locally
satisfied. The global physical outcome---the set of completed
transactions---is the configuration $\omega \in \mathcal{F}$ where all
local constraints are simultaneously met: the feasible set of the
constraint network, reached by distributed resolution without global
coordination.

\begin{remark}[Selection and collapse]
The structural identity between quantum collapse and natural selection
(\cref{ssec:biology}) is not accidental. In both cases, multiple
possibilities are explored (superposition / genetic variation),
constraints select which possibilities are realized (conservation laws /
fitness landscape), and the selection is local and distributed (each
absorber / each organism evaluates constraints independently). DCR
identifies both as instances of the same universal process, differing
only in the physical substrate and timescale.
\end{remark}

\begin{remark}[Discrete ontic structure and micro-choices]\label{rem:micro-choices}
The DCR picture of quantum mechanics does not require the continuum
structure of canonical quantum theory.
\citet{powers2024statistical} model measurement events as event
networks whose nodes and edges are built from finite base-2 (and
base-4/base-16) symbol sequences with XOR-like (addition modulo two)
composition.  Observable quantum numbers correspond to symbol
\emph{counts}---coarse summaries of the underlying sequences---while
the ordering of symbols within each sequence remains hidden.  This
hidden ordering is the source of non-determinism (in their phrase:
``counts are generally observable, but sequences are not'')
\citep{powers2024statistical}.

In DCR terms, the space of admissible ontic configurations (all
symbol orderings consistent with the quantum numbers) is the
\emph{exploration space}; the contextual compatibility
conditions---which orderings are consistent with both observers'
measurement events---are the \emph{constraints}; and the observed
probability distribution, given by relative frequencies of surviving
configurations, is the \emph{stabilized pattern}.  The individual
symbol orderings are \emph{micro-choices}: local, hidden degrees of
freedom whose structured resolution produces the macroscopic outcome.

For finite sequence length~$n$, the model predicts small but
unavoidable deviations from canonical QM due to discrete granularity
(e.g., rotation angles are effectively rational-valued), with
improved agreement as~$n$ increases.  \citet{powers2024statistical}
propose optical tabletop tests to constrain these $n$-dependent
deviations.  Crucially, the continuity of standard quantum mechanics
is never empirically confirmed---all measurement data is inherently
discrete---so the finite-$n$ model is not an approximation to the
``true'' continuous theory but a candidate for the more fundamental
description.  This supports the DCR framework's assumption of finite
discrete components (\cref{rem:finiteness}): the continuum may be an
idealization of an underlying discrete cognitive process operating
through micro-choices.
\end{remark}

\subsection{Thermodynamic Self-Organization}\label{ssec:thermo}

We formalize Rayleigh--B{\'e}nard convection as a cognitive system,
demonstrating that the verification of DCR conditions can be carried out
with full mathematical rigor---not merely by metaphorical re-description.

Consider a fluid layer between horizontal plates, heated from below
($T_H$) and cooled from above ($T_C$), in the Boussinesq approximation
\citep{chandrasekhar1961hydrodynamic}. We discretize the fluid domain on a
regular $d$-dimensional lattice with $N$ parcels and spacing $h$.

\begin{proposition}[B{\'e}nard Convection is Cognitive]\label{prop:benard}
For Rayleigh number $\mathrm{Ra} > \mathrm{Ra}_c$ (above the convective
instability threshold), the stochastic lattice Boussinesq system with
thermal fluctuations constitutes a cognitive system
$\mathcal{C} = (\mathcal{N}, \{X_t\}, \{f_s\}, \mathcal{A})$ in the
sense of \cref{def:cognitive-system}.
\end{proposition}

\begin{proof}
We construct the DCR tuple and verify conditions
\ref{cond:drift}--\ref{cond:full-support} of \cref{def:combined}.

\textbf{Constraint network.}
Let $S = \{1,\ldots,N\}$ index the parcels, with state space
$D_s = [-v_{\max}, v_{\max}]^d \times [T_C, T_H]$ for each $s$
(velocity and temperature, bounded by the energy balance). The
configuration space $\Omega = \prod_s D_s$ is compact. The interaction
graph $G$ is lattice adjacency (connected for $N \geq 2$). For each edge
$e = \{s,s'\} \in E$, the constraint relation $R_e$ encodes the
discretized Boussinesq conservation laws at the interface:
$(\omega_s, \omega_{s'}) \in R_e$ iff the discrete incompressibility
condition $\nabla^h_{ss'} \cdot \mathbf{v} = 0$, the discrete momentum
balance
$\nu\,\nabla^{h,2}_{ss'}\mathbf{v}
 - (\mathbf{v}\cdot\nabla^h_{ss'})\mathbf{v}
 + \beta(T-T_{\mathrm{ref}})\mathbf{g}
 = \nabla^h_{ss'} p$,
and the discrete energy balance
$\kappa\,\nabla^{h,2}_{ss'}T
 = (\mathbf{v}\cdot\nabla^h_{ss'})T$
are satisfied at the $\{s,s'\}$ interface, where $\nabla^h_{ss'}$ and
$\nabla^{h,2}_{ss'}$ denote the standard finite-difference gradient and
Laplacian operators, $\nu$ is kinematic viscosity, $\kappa$ is thermal
diffusivity, $\beta$ is the thermal expansion coefficient, and
$\mathbf{g}$ is gravitational acceleration.

\textbf{Violation.}
The pairwise violation $v_e(\omega_s, \omega_{s'})$ is the sum of squared
residuals of the three conservation equations at the $\{s,s'\}$ interface.
Then $v_e \geq 0$ with equality iff the steady-state Boussinesq equations
are locally satisfied, and $\Viol$ is continuous on compact $\Omega$.

\textbf{Dynamics.}
The resolution kernel $R$ is a semi-implicit Gauss--Seidel sweep of the
discretized Boussinesq equations: each parcel updates its velocity and
temperature using only the current states of its lattice neighbors,
satisfying the locality requirement of \cref{def:resolution}. The
exploration kernel $E$ adds Gaussian noise of variance
$\sigma^2 \propto k_B T_{\mathrm{ref}}/(\rho\, h^d)$ (fluctuating
hydrodynamics), projected onto $\Omega$:
\[
  E(\omega, \cdot) = \mathrm{Law}\!\bigl(
    \Pi_\Omega(\omega + \sigma\,\boldsymbol{\xi})\bigr),
  \qquad \boldsymbol{\xi} \sim \mathcal{N}(0, I_{N(d+1)}).
\]

\textbf{Verification of conditions.}
\begin{enumerate}[nosep,label=(\alph*)]
  \item \emph{Drift.} The energy functional
    $\mathcal{E}(\omega) = \sum_s\bigl[\tfrac{1}{2}|\mathbf{v}_s|^2
    + \tfrac{1}{2}|T_s - T_{\mathrm{lin},s}|^2\bigr]$
    (where $T_{\mathrm{lin}}$ is the linear conduction profile) satisfies
    \[
      \mathcal{E}(\omega^{(t+1)}) \leq \mathcal{E}(\omega^{(t)})
      - \Delta t\bigl[\nu\,\lVert\nabla^h\mathbf{v}\rVert^2
      + \kappa\,\lVert\nabla^h\theta\rVert^2\bigr]
      + \Delta t\,\mathrm{Ra}\,(\theta, v_z)
    \]
    under the resolution step, where $\theta = T - T_{\mathrm{lin}}$.
    By the discrete Poincar{\'e} inequality
    ($\lVert\nabla^h u\rVert^2 \geq \lambda_1\lVert u\rVert^2$ with
    $\lambda_1 > 0$ the spectral gap of the graph Laplacian), the
    dissipative terms dominate the buoyancy source in a neighborhood of
    the convection roll attractor, yielding the drift condition with
    rate $\alpha \sim \Delta t\,\min(\nu,\kappa)\,\lambda_1$. Near the
    attractor, $\Viol$ and $\mathcal{E}$ have comparable Hessians (by
    elliptic regularity of the linearized Boussinesq operator), so the
    drift transfers to $\Viol$.
  \item \emph{Bounded exploration.} $\Omega$ is compact and $\Viol$ is
    continuous, so
    $\int\Viol(\omega')\,E(\omega,d\omega') \leq \max_\Omega\Viol < \infty$.
  \item \emph{$\varphi$-irreducibility.} The Gaussian kernel $E$ has
    positive density on $\mathrm{int}(\Omega)$, so
    $K(\omega,A) \geq \epsilon\,E(\omega,A) > 0$ for any $A$ with
    positive Lebesgue measure $\lambda(A) > 0$. The chain is
    $\lambda$-irreducible.
  \item \emph{Aperiodicity.} Immediate from the positive-density
    transition kernel on a continuous state space.
  \item \emph{Weak Feller.} The Boussinesq update is polynomial in
    $\omega$ and neighbor states (hence continuous); the Gaussian density
    is smooth. Their convex combination $K$ is weak Feller.
  \item \emph{Full exploration support.} The Lebesgue-equivalent
    irreducibility measure charges every open set, in particular those
    meeting $\mathcal{F}$.
\end{enumerate}

\textbf{Attractor and coherence.}
For $\mathrm{Ra} > \mathrm{Ra}_c$, the feasible set $\mathcal{F}$
(steady-state solutions of the discretized Boussinesq equations) includes
the convection roll patterns \citep{cross1993pattern}. The roll solutions
do not factor as a product $\prod_s F_s$: the constraint that rising hot
fluid at parcel $s$ requires sinking cool fluid at its lateral neighbor
$s'$ creates irreducible inter-component dependence. Since $G$ is
connected and $\mathcal{F}$ is non-factorable, \cref{thm:convergence}
yields convergence to a stationary distribution $\mu^*$ with
$\Coh(\mu^*) > 0$. The Lyapunov function is $L = \Viol + 1$, and the
convection rolls constitute the goal-stabilizing pattern $\mathcal{A}$.
\end{proof}

The convection pattern is \emph{not} at equilibrium (DCR correctly
excludes equilibrium), and it arises without any central controller
selecting the pattern. It is a cognitive system of depth~1.

\begin{remark}[Formalizability of other physical examples]
The quantum (\cref{ssec:quantum}), biological (\cref{ssec:biology}), and
neural (\cref{ssec:neural}) examples admit analogous formalizations. In
each case, the construction follows the same six-step template as
\cref{prop:benard}: identify components and pairwise constraints, define
the violation via squared residuals of the governing equations, specify
the resolution and exploration kernels, and verify conditions
\ref{cond:drift}--\ref{cond:full-support}. We present these examples
informally below, noting that the exploration mechanism (quantum
fluctuations, genetic mutation, stochastic neural firing) and constraint
structure (interaction Hamiltonians, fitness landscapes, synaptic weights)
change while the verification structure remains the same.
\end{remark}

\subsection{Biological Adaptation}\label{ssec:biology}

\begin{itemize}[nosep]
  \item \textbf{Components:} Organisms in a population.
  \item \textbf{Degrees of freedom:} Genotype/phenotype space.
  \item \textbf{Exploration:} Mutation, recombination, developmental noise.
  \item \textbf{Constraints:} Environmental fitness landscape, inter-organism
        competition, predator--prey relations.
  \item \textbf{Resolution:} Natural selection propagates constraints locally
        (each organism's survival depends on its local fitness, not a global
        optimization). This is inherently distributed.
  \item \textbf{Stable pattern:} Adapted species occupying fitness peaks---the
        coherent attractor of the evolutionary dynamics
        \citep{kauffman1993origins}.
\end{itemize}

Biological evolution is a cognitive system of depth $\geq 2$: the organisms
themselves are cognitive systems (metabolic constraint resolution), and the
population-level dynamics is a second layer of cognition.

\subsection{Neural Cognition}\label{ssec:neural}

\begin{itemize}[nosep]
  \item \textbf{Components:} Neurons (or neural populations).
  \item \textbf{Degrees of freedom:} Firing rates, membrane potentials,
        synaptic states.
  \item \textbf{Exploration:} Spontaneous activity, noise, stochastic
        neurotransmitter release.
  \item \textbf{Constraints:} Synaptic weights, lateral inhibition, top-down
        priors encoded in connectivity.
  \item \textbf{Resolution:} Local integration-and-fire dynamics; each neuron
        resolves its inputs against its threshold. Constraint propagation is
        distributed across the network.
  \item \textbf{Stable pattern:} Perceptual representations, motor plans,
        decisions---coherent attractors of the neural dynamics
        \citep{seth2021being}.
\end{itemize}

Neural cognition achieves high depth because the components (neurons) are
themselves biochemical cognitive systems, embedded in circuits that form
cognitive systems, embedded in areas, and so on up to whole-brain dynamics.

% ==========================================================================
\section{Recovery of Existing Frameworks}\label{sec:recovery}
% ==========================================================================

\subsection{Free Energy Principle as a Special Case}\label{ssec:fep-recovery}

\begin{proposition}[FEP Recovery]\label{prop:fep}
The Free Energy Principle is a special case of DCR obtained when:
\begin{enumerate}[nosep]
  \item The constraint network is bipartite, partitioned into ``internal''
        and ``external'' components with a Markov blanket boundary.
  \item The constraints encode a generative model
        $p(\tilde{s}, \psi \mid m)$ relating external causes $\psi$ to
        sensory observations $\tilde{s}$.
  \item The coherence measure is replaced by the negative variational free
        energy: $\Coh \mapsto -F = \mathbb{E}_q[\ln p(\tilde{s}, \psi)] -
        \mathbb{E}_q[\ln q(\psi)]$.
  \item The resolution dynamics is gradient descent on $F$
        (recognition dynamics).
\end{enumerate}
Under these specializations, DCR's ``explore--resolve--stabilize'' reduces to
FEP's ``prediction error minimization via active inference.''
\end{proposition}

\begin{proof}
We construct an explicit embedding of the FEP formalism into DCR.

\textbf{Step 1: Constraint network.}
Let $S = S_\mu \cup S_b \cup S_\eta$ be the decomposition into internal
($\mu$), blanket ($b$), and external ($\eta$) states. The Markov blanket
condition means $E$ contains no edges between $S_\mu$ and $S_\eta$ directly;
all coupling is mediated through $S_b$. This is a constraint network with
$G$ having the bipartite-through-blanket structure.

Define the constraint relations on blanket--internal edges via the generative
model: for $s \in S_\mu$, $s' \in S_b$,
\[
  R_{\{s,s'\}} = \{(\mu_s, b_{s'}) :
  p(\tilde{s}_{s'} \mid \mu_s) > 0\},
\]
encoding which internal states are consistent with which sensory observations.

\textbf{Step 2: Violation as surprise.}
The constraint violation functions are:
\[
  v_{\{s,s'\}}(\mu_s, b_{s'}) = -\ln p(\tilde{s}_{s'} \mid \mu_s).
\]
The total violation is then
$\Viol(\omega) = -\sum_{\{s,s'\}} \ln p(\tilde{s}_{s'} \mid \mu_s)$.
To connect this to the FEP's surprisal $-\ln p(\tilde{s} \mid \mu)$, we
assume the generative model factorizes over blanket components conditioned
on internal states:
$p(\tilde{s} \mid \mu) = \prod_{s'} p(\tilde{s}_{s'} \mid \mu_{s(s')})$,
where $s(s')$ denotes the internal component coupled to blanket component
$s'$. Under this \emph{conditional independence} assumption (standard in
mean-field formulations of FEP), the sum reduces to:
$\Viol(\omega) = -\ln \prod_{s'} p(\tilde{s}_{s'} \mid \mu_{s(s')})
= -\ln p(\tilde{s} \mid \mu)$---the surprisal.

The variational free energy $F = \mathbb{E}_q[-\ln p(\tilde{s}, \psi)] +
\mathbb{E}_q[\ln q(\psi)]$ satisfies $F \geq -\ln p(\tilde{s})$ (by the
non-negativity of KL divergence), so $F$ is an upper bound on the surprisal,
hence on $\Viol$.

\textbf{Step 3: Resolution as free energy minimization.}
The FEP's recognition dynamics---gradient descent on $F$ with respect to
internal parameters---is a local update rule: each internal state $\mu_s$
adjusts based on its blanket neighbors. This satisfies the drift condition
\ref{cond:drift} because gradient descent on a smooth function bounded below
yields $\mathbb{E}[F_{t+1}] \leq F_t - \alpha \|\nabla F\|^2$ for suitable
step size, and $\Viol \leq F$ inherits the decrease.

\textbf{Step 4: Exploration as active inference.}
FEP's active inference includes epistemic actions---perturbations to blanket
states that sample the environment. These provide the exploration kernel $E$:
the system probes configurations that might reduce uncertainty, ensuring
accessibility of low-violation regions.

\textbf{Step 5: Attractor.}
The attracting set under FEP is the set of internal states where
$F$ is minimized, i.e., $q(\psi) \approx p(\psi \mid \tilde{s})$. This is
a feasible configuration (minimal violation) and is coherent since internal
states are statistically coupled through the shared generative model.

Hence the FEP system $(\{S_\mu, S_b, S_\eta\},$ bipartite $G$, recognition
dynamics, epistemic exploration$)$ is a DCR cognitive system under the
specializations stated.
\end{proof}

DCR is strictly more general than FEP in two ways: (1)~it does not require
a bipartite structure with a Markov blanket, and (2)~it does not require
the constraints to be expressible as a generative model. Physical constraint
resolution (e.g., decoherence, convection) need not involve
``inference'' in any Bayesian sense.

\subsection{Integrated Information Theory as a Special Case}\label{ssec:iit-recovery}

\begin{proposition}[IIT Recovery]\label{prop:iit}
The integrated information $\Phi$ of IIT~2.0
\citep{tononi2004information} is recoverable from DCR's coherence measure
under the following specializations:
\begin{enumerate}[nosep]
  \item The constraint network encodes the transition probability matrix
        (TPM) of IIT: for each edge $\{s, s'\}$, the constraint $R_{\{s,s'\}}$
        encodes which state transitions of $s$ are compatible with the current
        state of $s'$.
  \item The analysis is restricted to a single time step (the TPM acts once).
  \item Coherence is refined to its irreducible component via the minimum
        information partition (MIP).
\end{enumerate}
\end{proposition}

\begin{proof}
\textbf{Step 1: From DCR coherence to total correlation.}
DCR's coherence measure (\cref{def:coherence}) is the multi-information
$\Coh(\mu) = D_{\mathrm{KL}}(\mu \,\|\, \bigotimes_s \mu_s)$, which
quantifies the total statistical dependence among components.

\textbf{Step 2: From total correlation to integrated information.}
IIT~2.0 defines $\Phi$ using KL divergence as follows. For a system in
state $x$ with TPM $T$, let $\mu_x = p(X_{t+1} \mid X_t = x)$ be the
one-step conditional distribution over successor states. For a bipartition
$\pi$ that cuts $S$ into parts $A$ and $B$, define the partitioned
distribution $p_\pi(X_{t+1} \mid x) = p(X^A_{t+1} \mid x) \otimes
p(X^B_{t+1} \mid x)$, which severs all inter-part dependencies. Then:
\[
  \Phi(x) = \min_{\pi \in \mathcal{P}}
  D_{\mathrm{KL}}\!\bigl(\mu_x \;\|\; p_\pi(\cdot \mid x)\bigr),
\]
where $\mathcal{P}$ is the set of bipartitions. Since
$D_{\mathrm{KL}}(\mu_x \| \bigotimes_s (\mu_x)_s) = \Coh(\mu_x)$ and
$D_{\mathrm{KL}}(\mu_x \| p_\pi(\cdot \mid x))$ measures only the
inter-part dependence (the intra-part dependencies within $A$ and $B$
cancel), we obtain:
\[
  \Phi(x) = \min_{\pi \in \mathcal{P}} \bigl[
    \Coh(\mu_x) - \Coh_A(\mu_x) - \Coh_B(\mu_x)
  \bigr],
\]
where $\Coh_A, \Coh_B$ denote the multi-information within each part.
That is, $\Phi$ extracts the \emph{irreducible} component of DCR's
coherence---the inter-part dependence that survives every possible
bipartition.

\textbf{Step 3: Static vs.\ dynamic.}
IIT computes $\Phi$ at a single time step. DCR's coherence is defined on
the stationary distribution $\mu^*$, which integrates over the full
dynamical trajectory. The IIT measure is recovered by restricting $\mu$
to the conditional distribution at a single step.

Hence $\Phi$ is a refinement of $\Coh$: it subtracts the reducible
component. DCR's $\Coh > 0$ is necessary for $\Phi > 0$ (since $\Phi \leq
\Coh$), but $\Coh > 0$ does not imply $\Phi > 0$ (a system can have
statistical dependencies that are fully decomposable). In this sense, IIT
imposes a \emph{stricter} coherence criterion than DCR's default measure.
\end{proof}

\begin{remark}[IIT versions]
The recovery above targets IIT~2.0, which uses KL divergence as its
distance measure. IIT~3.0 \citep{tononi2016integrated} replaces KL
divergence with the earth mover's distance (Wasserstein metric) and
defines $\Phi$ over cause--effect structures rather than single
distributions. The structural relationship---$\Phi$ as irreducible
coherence---still holds conceptually, but the formal identity with
DCR's $\Coh$ requires additional metric-space machinery that we do not
develop here. IIT~4.0 further introduces dynamical aspects that bring it
closer to DCR's process-level account, suggesting deeper convergence
between the frameworks at the level of recent formulations.
\end{remark}

DCR extends IIT in two directions: (1)~it provides a \emph{process-level}
account of how coherence arises through exploration and resolution, rather
than merely measuring it at a single time step; and (2)~it defines cognition
for systems where $\Phi$ is intractable (the computation is
$O(2^n)$) but the DCR triad---exploration, resolution, convergence to
coherent attractors---is empirically observable.

% ==========================================================================
\section{Predictions and Falsifiability}\label{sec:predictions}
% ==========================================================================

A framework that explains everything predicts nothing. DCR makes the following
falsifiable claims:

\begin{enumerate}
  \item \textbf{Coherence--exploration tradeoff.} In any cognitive system,
        there exists an optimal regime where exploration rate and constraint
        strength are balanced. Too much exploration (relative to constraint
        strength) yields incoherent dynamics; too much constraint yields
        rigid, brittle systems that fail to adapt. This predicts a universal
        inverted-U relationship between exploration rate and cognitive
        performance, testable in neural systems (cf.\ stochastic
        resonance \citep{gammaitoni1998stochastic}), evolutionary
        simulations, and optimization algorithms.

  \item \textbf{Depth predicts adaptability.} Systems with greater cognitive
        depth $\delta$ (\cref{def:depth}) should exhibit greater adaptability
        to novel environments, because deeper nesting provides more levels at
        which exploration--resolution can occur. This is testable: compare the
        adaptability of systems with different organizational depths (e.g.,
        single-celled vs.\ multicellular organisms, shallow vs.\ deep neural
        networks, flat vs.\ hierarchical organizations).

  \item \textbf{Critical constraint density.} There exists a critical density
        of constraints $|E|/|S|$ below which the system cannot sustain coherent
        attractors and above which the system becomes rigid. This parallels the
        satisfiability phase transition in random constraint satisfaction
        problems \citep{mezard2002random}, where a sharp transition from
        under-constrained (many solutions, low coherence) to over-constrained
        (no solutions, frozen dynamics) occurs at a critical clause-to-variable
        ratio. DCR predicts that this transition coincides with maximal
        cognitive capacity: near the critical point, the system exhibits
        signatures of self-organized criticality \citep{bak1987self}---power-law
        distributions of attractor sizes, long-range correlations, and maximal
        susceptibility. The novel prediction beyond the SAT literature is that
        this critical regime should also maximize coherence $\Coh(\mu^*)$
        and support the deepest cognitive nesting $\delta$. This is testable
        in constraint satisfaction problems and neural network models.

  \item \textbf{Coarse-graining preserves cognitive signatures.} If DCR is
        correct, then empirically measured coherence, exploration rates, and
        convergence timescales should obey scaling laws across levels of
        description of the same system (e.g., single-neuron vs.\ population
        vs.\ whole-brain dynamics). Specifically, the ratio of exploration
        timescale to resolution timescale should be approximately preserved
        under coarse-graining.
\end{enumerate}

% ==========================================================================
\section{Discussion}\label{sec:discussion}
% ==========================================================================

\subsection{The Cosmos as Cognitive}

If DCR is correct, then cognition is not an emergent property of brains---it is
what physics \emph{does}. The offer wave explores all possible absorbers; the
Wheeler--Feynman handshake resolves conservation constraints; the completed
transaction stabilizes into a classical fact. Thermal fluctuations explore the
space of flow configurations; the Navier--Stokes equations resolve constraints
locally between neighboring parcels; convection rolls stabilize. Mutation
explores genotype space; natural selection resolves fitness constraints;
adapted species stabilize. The same formal process, recurring at every
scale, connected by the coarse-graining construction.

The TIQM framing (\cref{ssec:quantum}) reveals a further unity: what physics
calls ``collapse'' and what biology calls ``selection'' are not merely
analogous but structurally identical---both are instances of distributed
constraint resolution in which multiple possibilities are explored and
local constraints determine which are realized (see \cref{ssec:quantum},
Remark). The retrocausal structure of the transactional interpretation
suggests that constraint resolution need not respect the arrow of time;
it is a relation among boundary conditions, not a process confined to one
temporal direction.

The discrete ontic model of \citet{powers2024statistical} lends additional
support to this picture.  If quantum probabilities arise from counting
admissible configurations of binary sequences---\emph{micro-choices} at
the level of symbol orderings---then what physics calls a ``quantum state''
is already a coarse-grained summary of a discrete constraint resolution
process (\cref{rem:micro-choices}).  The continuum of Hilbert space is
recovered only in the limit $n \to \infty$; at every finite scale the
system is a finite constraint network undergoing exploration, resolution,
and stabilization.  This dissolves the objection that DCR's discrete
formalism cannot capture continuous physics: the continuity is emergent,
not fundamental.

This is not panpsychism in the traditional sense. We do not claim that an
emitter--absorber pair ``has experiences.'' We claim that the transaction
by which a photon is emitted and absorbed is \emph{the same kind of
process} as the one by which a neuron participates in perception---formally,
structurally the same, as verified through the explicit construction in
\cref{prop:benard} and the structural mappings of
\cref{ssec:quantum,ssec:biology,ssec:neural}. ``Cognition'' is the name we
give to this process. Whether one wishes to call this ``experience'' at the
quantum level is a separate philosophical question that DCR does not
adjudicate.

\subsection{Relationship to Process Philosophy}

DCR has deep resonances with Whitehead's process philosophy
\citep{whitehead1929process}, which held that reality consists not of
substances but of ``actual occasions''---events of experience that
``prehend'' (take account of) their environment and ``concresce'' into
definite outcomes. In DCR language: prehension is exploration of degrees of
freedom given the constraints imposed by neighboring occasions, and
concrescence is the resolution into a coherent, stabilized pattern.

The TIQM framing sharpens this resonance considerably. A Wheeler--Feynman
transaction is arguably the closest physical realization of a Whiteheadian
actual occasion: a discrete event in which multiple possibilities are
explored (the offer wave prehends all potential absorbers), constraints are
propagated bidirectionally (the confirmation wave), and a definite outcome
concresces (the completed transaction). The retrocausal structure of TIQM
mirrors Whitehead's insistence that actual occasions are not built up
sequentially from past to future but are constituted by their relations
to both past and future occasions. DCR, read through TIQM, can be
understood as a mathematization of process ontology in which each
transaction is an actual occasion and the constraint network is the nexus
of prehensive relations.

\subsection{Implications for Artificial Intelligence}

Current AI systems (large language models, reinforcement learning agents)
implement the DCR triad in restricted form: stochastic sampling (exploration),
gradient descent or constraint propagation (resolution), convergence to
low-loss configurations (stabilization). DCR predicts that the ``intelligence''
of these systems is bounded by their cognitive depth: the number of nested
levels at which the explore--resolve--stabilize cycle operates simultaneously.
This suggests that advances in AI may come not from scaling individual layers
but from increasing organizational depth---more levels of nested constraint
resolution.

\subsection{Limitations and Open Problems}

\begin{enumerate}
  \item \textbf{Timescale separation.} The closure theorem
        (\cref{thm:closure}) requires timescale separation between intra-group
        and inter-group dynamics. While this condition holds in many physical
        systems (atomic vs.\ molecular, synaptic vs.\ network), proving closure
        under weaker conditions---overlapping timescales, continuous-time
        limits, or stochastic timescale ratios---remains open. The convergence
        rates derived in \cref{lem:macro-drift} depend on the separation
        parameter $\eta$; quantifying this dependence precisely for specific
        physical systems is an important next step.

  \item \textbf{Quantitative predictions.} While DCR predicts qualitative
        relationships (inverted-U, depth--adaptability, critical constraint
        density), deriving precise quantitative predictions requires
        specifying the constraint structure of particular physical systems,
        which is a substantial empirical program.

  \item \textbf{The goal problem.} DCR defines goals as attractors of the
        dynamics, which avoids teleology. But this means that any attractor
        counts as a ``goal,'' including pathological ones (e.g., a dead
        organism is a stable attractor of biochemical dynamics). A richer
        notion of goal---perhaps involving the \emph{maintenance} of
        exploration capacity, connecting to autopoiesis---may be needed.

  \item \textbf{Temporal structure and retrocausality.} The TIQM framing
        of quantum DCR (\cref{ssec:quantum}) involves advanced waves
        propagating backward in time, suggesting that constraint resolution
        can be atemporal---a relation among boundary conditions rather than
        a process with a definite temporal direction. The current DCR
        formalism (\cref{sec:framework}) is built on forward-time Markov
        chains, which cannot accommodate retrocausal constraint propagation.
        Extending the framework to atemporal or bidirectional constraint
        resolution---perhaps using the two-state vector formalism or
        path-integral methods---is needed to fully capture the quantum case
        and may reveal a deeper temporal structure underlying the DCR triad.

  \item \textbf{Consciousness.} DCR is a theory of cognition, not of
        consciousness. It explains the process by which systems explore,
        resolve, and stabilize, but does not address the ``hard problem''
        \citep{chalmers1995facing} of why any of this is accompanied by
        subjective experience. DCR is compatible with, but does not entail,
        the identity of cognition and consciousness.
\end{enumerate}

% ==========================================================================
\section{Conclusion}\label{sec:conclusion}
% ==========================================================================

We have presented the Distributed Constraint Resolution (DCR) framework, a
formal, scale-free characterization of cognition as the process by which
components explore degrees of freedom and converge through distributed
constraint resolution into coherent, goal-stabilizing patterns. We have shown
that:

\begin{enumerate}[nosep]
  \item The framework is mathematically precise, built on constraint networks,
        stochastic dynamics, and information-theoretic coherence
        (\cref{sec:framework}).
  \item Under timescale separation, it is closed under coarse-graining,
        dissolving the combination problem and providing a natural measure
        of cognitive depth (\cref{sec:scale-free}).
  \item Fundamental physical processes satisfy the DCR axioms: rigorously
        for thermodynamic self-organization (\cref{prop:benard}), and
        structurally for quantum transactions, biological adaptation, and
        neural dynamics (\cref{sec:physics}). The quantum case, framed
        through the Transactional Interpretation, reveals that wavefunction
        collapse and natural selection are structurally identical instances
        of distributed constraint resolution. The discrete ontic model of
        \citet{powers2024statistical} provides independent evidence that
        quantum mechanics is compatible with---and may emerge from---the
        kind of finite combinatorial structure that DCR assumes
        (\cref{rem:micro-choices}).
  \item The Free Energy Principle and Integrated Information Theory are
        recoverable as special cases (\cref{sec:recovery}).
  \item The framework makes falsifiable predictions about coherence--exploration
        tradeoffs, depth--adaptability relationships, and critical constraint
        densities (\cref{sec:predictions}).
\end{enumerate}

If DCR is correct, then cognition is not a biological accident but a
fundamental feature of physical reality---the process by which the universe
explores its own degrees of freedom and resolves into the coherent structures
we observe at every scale. The offer wave and the mutation, the handshake
and the selection, the transaction and the adapted species, the symbol
ordering and the quantum outcome: one process, many substrates.

\bigskip
\bibliographystyle{plainnat}
\bibliography{references}

\end{document}

