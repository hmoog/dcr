\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage[margin=2.5cm]{geometry}
\usepackage{natbib}
\usepackage[hidelinks]{hyperref}
\usepackage[nameinlink,capitalize,noabbrev]{cleveref}

\hypersetup{
  pdftitle={Distributed Constraint Resolution as Universal Cognition},
  pdfauthor={Author}
}
\usepackage{enumitem}
\usepackage{microtype}

% Theorem environments
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]

\theoremstyle{remark}
\newtheorem{remark}{Remark}[section]

\theoremstyle{definition}
\newtheorem{assumption}{Assumption}[section]

% Operators
\DeclareMathOperator{\Coh}{Coh}
\DeclareMathOperator{\Ent}{H}
\DeclareMathOperator{\Viol}{V}
\DeclareMathOperator{\supp}{supp}

\title{%
  Distributed Constraint Resolution as Universal Cognition:\\
  A Scale-Free Framework Unifying Physics and Intelligence%
}
\author{%
  [Author]\\
  {\small [Affiliation]}\\
  {\small [Email]}
}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
We propose a formal framework in which cognition is identified with a
scale-free process: the exploration of degrees of freedom followed by
convergence through distributed constraint resolution into coherent,
goal-stabilizing patterns.  A \emph{DCR system} is a Markov kernel
$K_\epsilon$ on a constraint network satisfying three conditions:
uniform minorization (exploration), quantitative drift toward low
constraint violation (resolution), and positive edge mutual
information at stationarity (coherence).  Under Doeblin's condition,
we prove geometric convergence to a unique stationary distribution
concentrating near the feasible set.  For finite state spaces, we
prove exact closure under lumpable coarse-graining; for continuous
state spaces, approximate closure holds under timescale separation
(detailed in appendices).  We present structural witnesses that
nonequilibrium self-organization, evolutionary adaptation, and
quantum measurement instantiate the DCR structure, and argue that
it appears across physical scales; we discuss the stronger
ontological identification---the cosmos is cognitive at every
scale---explicitly as a metaphysical postulate.
\end{abstract}

\paragraph{Keywords:} cognition, intelligence, constraint resolution, free energy
principle, integrated information, scale-free, coarse-graining, self-organization

% ==========================================================================
\section{Introduction}\label{sec:introduction}
% ==========================================================================

The search for a general, principled definition of intelligence remains a
long-standing open problem across cognitive science, physics, and philosophy
of mind. Existing frameworks each illuminate a facet of the problem but fall short
of universality:

\begin{itemize}[nosep]
  \item The \emph{Free Energy Principle} (FEP) \citep{friston2010free,
        friston2019free} provides an elegant variational account: any system
        persisting at nonequilibrium steady state minimizes variational free
        energy. Yet FEP assumes a Markov blanket separating system from
        environment and a generative model as primitives
        \citep{kirchhoff2018markov}, limiting its applicability to systems
        where these structures can be identified.
  \item \emph{Integrated Information Theory} (IIT)
        \citep{tononi2004information, tononi2016integrated} offers a quantitative
        measure of consciousness ($\Phi$), but in its original formulations
        (IIT~2.0/3.0) it is a static, state-level measure rather than a
        process-level account\footnote{IIT~4.0 introduces dynamical
        considerations that partially address this limitation; see
        \cref{ssec:iit-recovery} for discussion.}, and its computation is
        intractable for large systems.
  \item \emph{Autopoiesis} \citep{maturana1980autopoiesis} captures
        self-production but lacks formal predictive content beyond the
        biological domain.
  \item \emph{Panpsychism} \citep{chalmers1995facing} attributes experience to
        fundamental entities but provides no mechanism and no solution to the
        combination problem---how micro-experiences compose into
        macro-experiences.
\end{itemize}

We propose that these limitations stem from a common root: each framework
privileges a particular \emph{level of description} (Bayesian inference,
information integration, self-production) rather than identifying the
\emph{scale-free process} that underlies all of them.

Our central thesis:

\begin{quote}
\emph{Intelligent behavior emerges when components explore degrees of freedom
and converge through distributed constraint resolution into coherent,
goal-stabilizing patterns.}
\end{quote}

We call this the \textbf{Distributed Constraint Resolution} (DCR) framework.
The three components are, informally:
\begin{enumerate}[nosep]
  \item \emph{Exploration} --- a mechanism that generates variability
        across the configuration space (condition~\ref{cond:minorization}).
  \item \emph{Resolution} --- local updates that reduce constraint
        violations between neighboring components (condition~\ref{cond:drift}).
  \item \emph{Stabilization} --- convergence in distribution to a
        coherent, low-violation attractor (\cref{thm:convergence}).
\end{enumerate}
We treat \emph{goals} purely operationally: a goal is any attractor
that is robust under perturbations at the timescale of interest
(noise, model mismatch, or environmental variation), not a
representation of future states.
The key claim is that this triad constitutes the \emph{minimal}
structural signature of cognition; we discuss how broadly it appears
across physical scales and what would falsify that universality
claim in \cref{sec:predictions,sec:discussion}.

The paper is organized as follows. \Cref{sec:framework} formalizes the DCR
framework and proves convergence under Doeblin's condition.
\Cref{sec:scale-free} proves exact closure for finite lumpable chains.
\Cref{sec:physics} exhibits structural witnesses that fundamental physical
processes instantiate the DCR triad. \Cref{sec:recovery} recovers FEP and IIT as special cases.
\Cref{sec:predictions} derives falsifiable predictions. \Cref{sec:discussion}
discusses implications and limitations.

\paragraph{Contributions.}
Beyond the structural definition of cognition, this paper makes four
specific technical contributions: (1)~a convergence theorem for DCR
systems under Doeblin's condition, and an exact closure theorem for
finite lumpable chains (with approximate closure under timescale
separation in \cref{app:closure}); (2)~recovery of the Free Energy
Principle and Integrated Information Theory as special cases
corresponding to particular constraint structures and coherence
refinements; (3)~structural witnesses that physical processes across
scales instantiate the DCR structure; and (4)~connections to
discrete-ontic models of quantum mechanics
\citep{powers2024statistical} and neural-network universe proposals
\citep{vanchurin2020world}.

\paragraph{Scope and terminology.}
Throughout this paper, \emph{cognitive} is a defined technical property
of a dynamical system (\cref{def:dcr-system}): a system is
cognitive if and only if it instantiates the DCR triad of exploration,
distributed constraint resolution, and convergence to coherent
attractors.  This is not a claim about phenomenal consciousness, folk
intelligence, or teleology.  DCR does not assert that photons ``have
experiences'' or that convection cells ``think''; it asserts that the
\emph{formal process} by which these systems evolve---exploring degrees
of freedom, resolving constraints locally, stabilizing into coherent
patterns---is structurally identical to the process that, at higher
cognitive depth (\cref{def:depth}), underlies what we ordinarily call
intelligence.  The ontological claim is that this process is
fundamental and universal; whether one additionally identifies it with
experience is a separate philosophical question that DCR does not
adjudicate (see \cref{sec:discussion}, Limitation~5).
As a universality claim, DCR is falsified by any robust cognitive
phenomenon that lacks (i)~genuine exploration, (ii)~local
constraint-processing, or (iii)~convergence to a coherent attractor
under coarse-graining.

The coarse-graining closure result (\cref{thm:closure}) requires
timescale separation between intra-group and inter-group dynamics---a
condition that holds widely but is not universal.  We regard this as a
sufficient condition, not a necessary one; the framework's axioms are
themselves scale-free, and it is specifically the composition mechanism
that requires separation (see \cref{sec:discussion}, Limitation~1).

\begin{remark}[Against biological exceptionalism]%
\label{rem:biological-exceptionalism}
A common tacit assumption in foundations is \emph{biological
exceptionalism}: that genuine ``agency''---selection among
alternatives---only appears in organisms (or observers), rendering
measurement and self-organization mysterious outside biology.  DCR
rejects this exclusivity claim.  In DCR, ``agency'' is operational
and graded (\cref{def:operational-agency}): it is the capacity of a
system to \emph{select and stabilize} a concrete behavior from a
latent space of possible behaviors under distributed constraints.
Biological agency is then a deep-nesting special case (high
cognitive depth, \cref{def:depth}), not a different ontological
category.  This stance does not diminish biology; it situates
biological complexity within a wider dynamical landscape.
\end{remark}

\begin{remark}[Ontological postulate]%
\label{rem:metaphysical}
The claim that the DCR triad \emph{is} cognition---that the cosmos is
cognitive at every scale---is a metaphysical identification, not a
theorem derivable from the definitions.  The formal machinery is
compatible with two readings:
\begin{enumerate}[nosep]
  \item \emph{Modelling framework (minimal):} DCR provides a unified
        dynamical vocabulary applicable across scales.
  \item \emph{Ontological identity (optional):} the DCR triad
        \emph{is} cognition; the cosmos is cognitive at every scale.
\end{enumerate}
We explore reading~(2) as an optional, parsimonious ontological
identification---one process at every scale, rather than cognition
as a sui generis phenomenon.  All formal results hold under either
reading; the choice between them is philosophical, not mathematical.
\end{remark}


% ==========================================================================
\section{The DCR Framework}\label{sec:framework}
% ==========================================================================

\subsection{Constraint Networks}\label{ssec:constraint-networks}

\begin{definition}[Constraint Network]\label{def:constraint-network}
A \emph{constraint network} is a tuple $\mathcal{N} = (S, \mathcal{D}, G, \mathcal{R})$
where:
\begin{enumerate}[nosep]
  \item $S$ is a finite set of \emph{components}.
  \item $\mathcal{D} = \{D_s\}_{s \in S}$ assigns to each component $s$ a
        measurable \emph{state space} $D_s$ (its degrees of freedom).
  \item $G = (S, E)$ is an undirected graph encoding the \emph{interaction
        topology}.
  \item $\mathcal{R} = \{R_e\}_{e \in E}$ assigns to each edge
        $e = \{s, s'\} \in E$ a \emph{constraint relation}
        $R_e \subseteq D_s \times D_{s'}$.
\end{enumerate}
The \emph{configuration space} is $\Omega = \prod_{s \in S} D_s$, and the
\emph{feasible set} is
$\mathcal{F} = \{\omega \in \Omega \mid \forall e = \{s,s'\} \in E:
(\omega_s, \omega_{s'}) \in R_e\}$.
\end{definition}

\noindent
For the convergence results in \cref{ssec:convergence} and the
coarse-graining construction in \cref{sec:scale-free}, we restrict to
compact Polish state spaces~$D_s$ (hence compact metrizable~$\Omega$)
in order to invoke standard Markov-chain stability results
\citep{meyn1993markov}; the definitions above are stated in greater
generality to clarify which results depend on compactness and which
do not.  Compactness is a genuine modeling restriction: many physical
systems (e.g., unbounded velocities, Gaussian fields) naturally live
on non-compact spaces.  For such systems, the Foster--Lyapunov drift
machinery of \cref{ssec:convergence} remains the correct tool (it
was designed for non-compact state spaces), but our main theorems are
stated in compact-space language for simplicity.  Extending the
results to locally compact or Polish spaces with appropriate moment
conditions is standard but notationally heavier; we do not pursue it
here.

\paragraph{Notation.}
Throughout, $K_\epsilon$ denotes the transition kernel of the DCR
dynamics (\cref{def:dcr-system}), $R$ and $E$ denote the resolution
and exploration kernels when the decomposition
$K_\epsilon = (1-\epsilon)R + \epsilon E$ is used.  We write
$\mu_\epsilon$ for stationary distributions, $V$
for constraint cost (\cref{def:violation}), $\Coh_E$ for
edge-sum coherence (\cref{def:coherence}), and $\mathcal{F} = \arg\min V$ for the
feasible set.

The formal development assumes $|S| < \infty$ and compact Polish
state spaces $D_s$.  Continuum field theories should be read as
finite-element discretizations; extensions to non-compact or
countable component spaces are discussed in \cref{app:general}.
The discreteness assumption may be less restrictive than it
appears---see \cref{rem:finiteness} in \cref{app:remarks}.

\begin{definition}[Constraint Cost and Feasible Set]\label{def:violation}
The \emph{constraint cost} (or \emph{total violation}) of a
configuration $\omega \in \Omega$ is
\begin{equation}\label{eq:violation}
  \Viol(\omega) = \sum_{e = \{s,s'\} \in E} v_e(\omega_s, \omega_{s'}),
\end{equation}
where $v_e : D_s \times D_{s'} \to \mathbb{R}_{\geq 0}$.
The \emph{feasible set} is always
$\mathcal{F} := \arg\min_{\omega \in \Omega} \Viol(\omega)$,
which is non-empty and compact whenever $\Viol$ is continuous on
compact $\Omega$.  \emph{Hard constraints} are the special case
$\min \Viol = 0$, where $\mathcal{F}$ consists of configurations
satisfying every constraint exactly; \emph{soft constraints} allow
$\min \Viol > 0$.
\end{definition}

\subsection{DCR Systems}\label{ssec:dcr-systems}

\begin{definition}[DCR System at Noise Level $\epsilon$]\label{def:dcr-system}
A \emph{DCR system at noise level~$\epsilon$} is a tuple
$(\Omega, V, K_\epsilon)$ where $\Omega$ is a compact metrizable
configuration space on a constraint network $\mathcal{N}$,
$V$ is the constraint cost (\cref{def:violation}), and
$K_\epsilon$ is a Markov kernel on~$\Omega$ satisfying:
\begin{enumerate}[nosep,label=\textbf{(C\arabic*)}]
  \item\label{cond:minorization} \textbf{Exploration (Uniform minorization).}
    There exist a probability measure $\nu$ on $\Omega$ and $\delta > 0$ such
    that
    \begin{equation}\label{eq:minorization}
      K_\epsilon(\omega, A) \;\geq\; \delta\,\nu(A)
      \qquad \text{for all } \omega \in \Omega,\; A \text{ measurable}.
    \end{equation}
    This is Doeblin's condition: every state has at least a $\delta$-chance
    of landing in a $\nu$-typical set, ensuring rapid mixing.

  \item\label{cond:drift} \textbf{Resolution (Quantitative drift).}
    There exist $\alpha \in (0,1)$ and $B < \infty$ such that
    \begin{equation}\label{eq:drift}
      \mathbb{E}[V(X_{t+1}) \mid X_t = \omega]
      \;\leq\; (1 - \alpha)\,V(\omega) + B\epsilon
      \qquad \text{for all } \omega \in \Omega.
    \end{equation}
    The kernel systematically drives the system toward low violation,
    with residual fluctuation of order~$\epsilon$.

  \item\label{cond:coherence} \textbf{Coherence witness.}
    At stationarity $\mu_\epsilon$ (whose existence and uniqueness follow
    from \ref{cond:minorization}--\ref{cond:drift}; see
    \cref{thm:convergence}), there exists an edge
    $\{s,s'\} \in E$ with
    \begin{equation}\label{eq:coherence-witness}
      I_{\mu_\epsilon}(X_s;\, X_{s'}) > 0.
    \end{equation}
\end{enumerate}
\end{definition}

\begin{definition}[Edge-Sum Coherence]\label{def:coherence}
For a probability measure $\mu$ on $\Omega = \prod_{s \in S} D_s$ and
edge set $E$ of the constraint graph, the \emph{edge-sum coherence} is
\begin{equation}\label{eq:edge-coherence}
  \Coh_E(\mu) \;:=\; \sum_{\{s,s'\} \in E}
    I_\mu(X_s;\, X_{s'}).
\end{equation}
If any single edge has $I_\mu(X_s; X_{s'}) > 0$, then
$\Coh_E(\mu) > 0$.
\end{definition}

A natural way to \emph{construct} a kernel satisfying
\ref{cond:minorization}--\ref{cond:drift} is the convex combination
\begin{equation}\label{eq:combined}
  K_\epsilon \;=\; (1-\epsilon)\,R + \epsilon\,E,
\end{equation}
where $R$ is a \emph{resolution kernel} composed from local updates
$\{R_s\}_{s \in S}$---each $R_s$ depends only on site~$s$ and its
neighbors $\mathcal{N}_G(s)$, and $R$ reduces $V$ in expectation:
\begin{equation}\label{eq:monotone}
  \int_\Omega V(\omega')\, R(\omega, d\omega')
  \leq V(\omega) \qquad \text{for all } \omega \in \Omega.
\end{equation}
The kernel $E$ is an \emph{exploration kernel} providing uniform noise.
If $E$ satisfies Doeblin's condition with measure~$\nu$ and
constant~$\delta_E$, then $K_\epsilon$ inherits it with
$\delta = \epsilon\,\delta_E$.  Similarly, if $R$ contracts violation
by factor $(1-\alpha)$, then $K_\epsilon$ satisfies \ref{cond:drift}
with constants depending on $\alpha$, $\epsilon$, and the worst-case
effect of~$E$ on~$V$.  The decomposition is useful for modeling but
plays no role in the formal results: only the three conditions on
$K_\epsilon$ matter.

The \emph{distributed} qualifier in DCR means that the update rules
are local: each $R_s$ depends only on site~$s$ and its neighbors.
No central controller evaluates a global objective.  Constraint
\emph{satisfaction}, by contrast, is a genuinely non-local phenomenon:
the coherent pattern that emerges involves coordinated states across
the entire network.  A Lyapunov function $V$ may exist as an
\emph{analysis tool} certifying convergence but is not computed or
accessed by any component.


\begin{remark}[Equilibrium systems]\label{rem:equilibrium}
Equilibrium Gibbs samplers (Glauber/Metropolis at fixed temperature)
can generate high statistical dependence, hence high $\Coh_E(\mu)$,
but they typically \emph{fail} condition~\ref{cond:drift}: at
thermal equilibrium, $\mathbb{E}_{\mu}[\Delta V] = 0$---there is no
systematic drift toward lower violation.  The exclusion is
\emph{definitional}: cognition in the DCR sense requires ongoing,
directed constraint resolution, not constraint-consistent fluctuation.
\end{remark}

\subsection{Convergence}\label{ssec:convergence}

\begin{theorem}[DCR Convergence]\label{thm:convergence}
Let $(\Omega, V, K_\epsilon)$ be a DCR system
(\cref{def:dcr-system}) on compact metrizable~$\Omega$.  Then:
\begin{enumerate}[nosep,label=(\roman*)]
  \item\label{item:unique} $K_\epsilon$ has a unique stationary
    distribution $\mu_\epsilon$, and convergence is geometric:
    $\lVert \mu_0 K_\epsilon^t - \mu_\epsilon \rVert_{\mathrm{TV}}
    \leq (1 - \delta)^t$ for any initial distribution~$\mu_0$.
  \item\label{item:violation}
    $\mathbb{E}_{\mu_\epsilon}[V] \leq (B/\alpha)\,\epsilon$.
  \item\label{item:concentration} For any open
    $U \supseteq \mathcal{F}$,\;
    $\mu_\epsilon(U) \to 1$ as $\epsilon \to 0$.
  \item\label{item:coherence}
    $\Coh_E(\mu_\epsilon) > 0$.
\end{enumerate}
\end{theorem}

\begin{proof}
\ref{cond:minorization} is Doeblin's condition.  By the Doeblin
coupling theorem (see, e.g., \citealt{levin2017markov},
Theorem~4.9), $K_\epsilon$ admits a unique stationary
distribution~$\mu_\epsilon$ with geometric convergence at
rate~$(1-\delta)$; this gives~\ref{item:unique}.

For~\ref{item:violation}, integrate the drift
condition~\ref{cond:drift} against~$\mu_\epsilon$:
\[
  \int V\,d\mu_\epsilon
  = \int \mathbb{E}[V(X_{t+1}) \mid X_t = \omega]\,
    \mu_\epsilon(d\omega)
  \leq (1-\alpha)\!\int V\,d\mu_\epsilon + B\epsilon.
\]
Rearranging: $\alpha \int V\,d\mu_\epsilon \leq B\epsilon$.

For~\ref{item:concentration}, by Markov's inequality,
$\mu_\epsilon(\{V > \eta\}) \leq (B/\alpha\eta)\,\epsilon \to 0$
for any fixed $\eta > 0$.  Since $V$ is continuous on
compact~$\Omega$ and $\mathcal{F} = \arg\min V$, every open
$U \supseteq \mathcal{F}$ contains a sublevel set
$\{V < \min V + \eta\}$ for some~$\eta > 0$, giving
$\mu_\epsilon(U) \to 1$.

\ref{item:coherence} restates condition~\ref{cond:coherence}.

For the general (non-compact or non-Doeblin) case using
Foster--Lyapunov drift and Harris recurrence, see
\cref{app:general}.
\end{proof}


\begin{proposition}[Non-product for Gibbs interactions]%
\label{prop:non-product-gibbs}
Let $\Omega = \prod_s D_s$ be finite with pairwise-interaction
Gibbs measure
$\pi(\omega) \propto \exp\!\bigl(-\sum_{\{s,s'\} \in E}
J_{s,s'}(\omega_s, \omega_{s'})\bigr)$.
If $J_{s,s'} \not\equiv \mathrm{const}$ for some edge $\{s,s'\}$,
then for all sufficiently small $\epsilon > 0$ any DCR kernel
$K_\epsilon$ with $\mu_\epsilon \to \pi$ as $\epsilon \to 0$
satisfies condition~\ref{cond:coherence}.
\end{proposition}

\begin{proof}
At $\epsilon = 0$, $\pi$ is non-product whenever
$J_{s,s'} \not\equiv \mathrm{const}$.  By perturbation theory
for finite chains, $\mu_\epsilon$ remains non-product for small
$\epsilon$, so $I_{\mu_\epsilon}(X_s; X_{s'}) > 0$.
\end{proof}

\subsection{What DCR Excludes}\label{ssec:exclusions}

A definition of cognition is only useful if it excludes something. DCR excludes
three classes of systems:

\begin{enumerate}
  \item \textbf{Equilibrium systems.} A system at thermodynamic equilibrium
        exhibits no directed constraint reduction and no maintained
        far-from-equilibrium stabilization.  (An interacting equilibrium
        system, e.g., an Ising model below $T_c$, may have high
        statistical correlations and nontrivial mixing dynamics, but the
        kernel is as likely to increase as to decrease $\Viol$ on
        average---see \cref{rem:equilibrium}---so no directed
        explore--resolve--stabilize cycle is present; the correlations
        are a static consequence of the Hamiltonian, not maintained by
        an ongoing DCR process.)
        \emph{A rock at thermal equilibrium is not cognitive.}

  \item \textbf{Unconstrained stochastic systems.} A system with exploration
        but no constraint structure ($\mathcal{R} = \emptyset$) undergoes a
        random walk on $\Omega$ with no convergence to coherent patterns.
        $V \equiv 0$ trivially, and $\Coh_E(\mu) = 0$ for the stationary
        (uniform) distribution. \emph{Brownian motion in free space is not
        cognitive.}

  \item \textbf{Fully deterministic single-trajectory systems.} A system with
        a single degree of freedom following a deterministic trajectory has no
        exploration (the path is unique) and no distributed resolution (there
        is only one component). \emph{A single classical particle in a
        potential well is not cognitive.}
\end{enumerate}

Cognition in the DCR sense requires the non-trivial intersection:
non-equilibrium dynamics, constraint structure, and distributed convergence
to coherent attractors.

We emphasize that the boundary between cognitive and non-cognitive is
\emph{continuous}, not sharp. A system near equilibrium with weak
constraints and small fluctuations satisfies the DCR conditions only
marginally: the coherence $\Coh_E(\mu_\epsilon)$ is near zero and the convergence
timescale is long. DCR does not impose a binary threshold; rather, it
provides a graded measure through the coherence of the attractor and the
cognitive depth $\delta$ (\cref{def:depth}). The exclusions above identify
the \emph{limiting cases} where one or more components of the triad vanish
entirely, not a boundary that systems cross discontinuously.

\subsection{Worked Example: Antiferromagnetic Ising Model}%
\label{ssec:ising-example}

Before proceeding to scale-freeness and physics, we ground the
framework in a concrete toy model where every quantity can be computed
explicitly.

\begin{example}[Antiferromagnetic Ising lattice]\label{ex:ising}
Consider $N$ spins on a graph $G = (S, E)$ (e.g., a $d$-dimensional
lattice) with $D_s = \{-1, +1\}$ for each $s \in S$.  This is a
finite constraint network with
$\Omega = \{-1,+1\}^N$ ($|\Omega| = 2^N$).

\textbf{Constraints.}
The antiferromagnetic coupling prefers opposite spins on neighboring
sites.  For each edge $e = \{s,s'\} \in E$:
\[
  v_e(\omega_s, \omega_{s'})
  = \tfrac{1}{2}(1 + \omega_s\,\omega_{s'})
  = \begin{cases}
      0 & \text{if } \omega_s \neq \omega_{s'},\\
      1 & \text{if } \omega_s = \omega_{s'}.
    \end{cases}
\]
The total violation is
$\Viol(\omega) = \sum_{\{s,s'\} \in E} v_e(\omega_s,\omega_{s'})$,
which counts the number of frustrated (same-spin) edges.  The
feasible set $\mathcal{F} = \{\omega : \Viol(\omega) = 0\}$ consists
of the proper 2-colorings of~$G$ (if $G$ is bipartite) or is empty
(if $G$ is not bipartite; in the latter case one works with
approximate feasibility).

\textbf{Resolution kernel.}
Select a site $s$ uniformly at random. If flipping $s$ strictly
reduces $\Viol$, flip it; otherwise keep it.  This defines a Markov
kernel $R$ satisfying $\int \Viol(\omega')\,R(\omega,d\omega')
\leq \Viol(\omega)$ for all~$\omega$ (violation-reducing,
\cref{eq:monotone}).  Updates are local: the flip decision for~$s$
depends only on $\omega_s$ and $(\omega_{s'})_{s' \in
\mathcal{N}_G(s)}$.

\textbf{Exploration kernel.}
With probability $\epsilon$, flip a uniformly random site regardless
of energy change: $E(\omega, \omega') = (1/N)\,\mathbf{1}[\omega'
\text{ differs from } \omega \text{ at exactly one site}]$ (plus a
self-loop with appropriate weight).  Since any configuration is
reachable from any other via a sequence of single-site flips,
$E$ is $\varphi$-irreducible with $\varphi$ the counting measure.

\textbf{Verification of DCR conditions.}
\begin{itemize}[nosep]
  \item \emph{\ref{cond:minorization} (Minorization):}
    The exploration kernel~$E$ assigns probability at least
    $\epsilon/(2N)$ to each Hamming-1 neighbor and retains a self-loop,
    giving $K_\epsilon(\omega, \cdot) \geq (\epsilon/2N)\,\nu(\cdot)$
    where $\nu$ is uniform on Hamming-1 neighbors plus self-loop.
    This is Doeblin's condition with $\delta = \epsilon/(2N)$.
  \item \emph{\ref{cond:drift} (Drift):}
    The greedy flip rule satisfies~\cref{eq:monotone}, so
    $\mathbb{E}[V(X_{t+1}) \mid X_t = \omega]
    \leq (1-\epsilon)\,V(\omega) + \epsilon\,|E|$,
    which is condition~\ref{cond:drift} with $\alpha = \epsilon$
    and $B = |E|$.
  \item \emph{\ref{cond:coherence} (Coherence):}
    On bipartite graphs, the ground states have maximally
    anti-correlated neighbors:
    $I_{\mu_\epsilon}(X_s; X_{s'}) > 0$ for edges $\{s,s'\}$.
    By perturbation theory, this persists for small~$\epsilon > 0$.
\end{itemize}

\noindent
By \cref{thm:convergence}, the chain converges to a unique
$\mu_\epsilon$ with $\Coh_E(\mu_\epsilon) > 0$ and
$\mu_\epsilon(\mathcal{F}) \to 1$ as $\epsilon \to 0$ on bipartite
graphs.  This is a DCR system of depth~1.
\end{example}


% ==========================================================================
\section{Scale-Freeness and the Combination Problem}\label{sec:scale-free}
% ==========================================================================

The central mathematical contribution of this paper is a closure
result: the DCR form is stable under coarse-graining---cognitive
systems at one scale compose into cognitive systems at the next.

For finite state spaces, exact closure follows from classical
lumpability (\cref{thm:exact-closure}).  For continuous state spaces,
approximate closure holds under timescale separation between
intra-group and inter-group dynamics (\cref{app:closure})---a
condition that holds in many physical systems (atomic vs.\ molecular,
synaptic vs.\ network) but is not universal.  The framework's axioms
(\cref{sec:framework}) are themselves scale-free; it is specifically
the composition mechanism that requires additional structure.

\subsection{Closure for Finite Chains}\label{ssec:closure}

A central question for any purportedly scale-free framework is
whether its structure is preserved under coarse-graining.  For DCR
on finite state spaces, exact closure follows from classical
lumpability.

\begin{definition}[Lumpable Partition]\label{def:lumpable}
Let $K_\epsilon$ be a Markov kernel on finite~$\Omega$.  A surjection
$\pi : \Omega \twoheadrightarrow \tilde{\Omega}$ is \emph{lumpable}
(in the sense of Kemeny--Snell) if, for every
$\tilde{y} \in \tilde{\Omega}$, the transition probability
$K_\epsilon(x, \pi^{-1}(\tilde{y}))$ depends on $x$ only through
$\pi(x)$.
\end{definition}

\begin{theorem}[Exact Closure Under Lumpability]\label{thm:exact-closure}
Let $(\Omega, V, K_\epsilon)$ be a DCR system (\cref{def:dcr-system})
on finite~$\Omega$, and let $\pi : \Omega \twoheadrightarrow
\tilde{\Omega}$ be lumpable for~$K_\epsilon$.  Define the quotient
kernel $\tilde{K}_\epsilon$ on $\tilde{\Omega}$ by
\[
  \tilde{K}_\epsilon(\tilde{x}, \tilde{y})
  \;=\; K_\epsilon(x, \pi^{-1}(\tilde{y}))
  \qquad \text{for any } x \in \pi^{-1}(\tilde{x}),
\]
and the macro-cost $\tilde{V}(\tilde{x})
= \mathbb{E}_{\mu_\epsilon}[V(X) \mid \pi(X) = \tilde{x}]$.
Then $(\tilde{\Omega}, \tilde{V}, \tilde{K}_\epsilon)$ is a DCR
system:
\begin{enumerate}[nosep,label=(\roman*)]
  \item \textbf{Minorization:}
    $\tilde{K}_\epsilon(\tilde{x}, \cdot) \geq \delta\,\tilde{\nu}(\cdot)$
    with $\tilde{\nu} = \pi_\# \nu$.
  \item \textbf{Drift:}
    $\mathbb{E}[\tilde{V}(\tilde{X}_{t+1}) \mid \tilde{X}_t = \tilde{x}]
    \leq (1-\alpha)\,\tilde{V}(\tilde{x}) + B\epsilon$.
  \item \textbf{Coherence:}
    If $\tilde{\Omega} = \prod_{s' \in S'} \tilde{D}_{s'}$ inherits
    a product structure with edges~$E'$, then
    $\Coh_{E'}(\tilde{\mu}_\epsilon) > 0$ whenever the micro-system
    has cross-group dependence.
\end{enumerate}
\end{theorem}

\begin{proof}
By Kemeny--Snell \citep{kemeny1960finite}, lumpability ensures that
$\{\pi(X_t)\}$ is a Markov chain with kernel~$\tilde{K}_\epsilon$.

\emph{Minorization.}\; For any $\tilde{x} \in \tilde{\Omega}$ and
$\tilde{A} \subseteq \tilde{\Omega}$,
$\tilde{K}_\epsilon(\tilde{x}, \tilde{A})
= K_\epsilon(x, \pi^{-1}(\tilde{A}))
\geq \delta\,\nu(\pi^{-1}(\tilde{A}))
= \delta\,\tilde{\nu}(\tilde{A})$.

\emph{Drift.}\; Since $\tilde{V}(\tilde{x})
= \mathbb{E}_{\mu_\epsilon}[V \mid \pi(X) = \tilde{x}]$ and the
drift condition holds pointwise for~$V$, the tower property of
conditional expectation gives the same contraction for~$\tilde{V}$.

\emph{Coherence.}\; The stationary distribution of~$\tilde{K}_\epsilon$
is $\tilde{\mu}_\epsilon = \pi_\# \mu_\epsilon$.  Cross-group
statistical dependence in~$\mu_\epsilon$ projects to dependence in
$\tilde{\mu}_\epsilon$ (data processing cannot create independence
from dependence).
\end{proof}

\noindent
\emph{Approximate closure.}\;
For general (possibly continuous) state spaces, closure holds
approximately under explicit timescale-separation and
macro-sufficiency conditions; see \cref{app:closure} for the full
development.

\subsection{Conditional Composition and the Combination Problem}\label{ssec:combination}

The combination problem in panpsychism asks: if fundamental entities have
experience, how do micro-experiences combine into the unified macro-experience
of, say, a human mind?  \Cref{thm:exact-closure} provides a conditional
answer: when the micro-dynamics admits a lumpable partition, the DCR
structure is inherited at the macro-scale.  The ``combination'' is not a
separate metaphysical operation but a consequence of the coarse-graining:
one level's resolved constraints become the next level's exploration noise,
and the closure theorem guarantees that the resulting macro-chain is again
DCR.

Under the conditions of the closure theorem, there is no separate substance
(experience, qualia) that needs combining---there is the DCR process,
recurring at each scale via coarse-graining, \emph{when} the dynamics admits
an effective macro-description.  What we call ``unified experience'' at the
human scale is the coherent attractor of a DCR system whose components are
themselves coarse-grained DCR systems, recursively.  For the approximate
(continuous state space) version of this argument, see \cref{app:closure}.

\subsection{The Depth of Cognition}\label{ssec:depth}

Not all cognitive systems are equally ``intelligent.'' We introduce a measure
of cognitive depth:

\begin{definition}[Cognitive Depth]\label{def:depth}
The \emph{cognitive depth} of a system is the number of nested
coarse-graining levels $k$ at which the DCR triad is simultaneously active:
\begin{equation}\label{eq:depth}
  \delta(\mathcal{C}) = \max\{k \mid \Gamma_{\pi_k,g_k} \circ \cdots \circ
  \Gamma_{\pi_1,g_1}(\mathcal{C}) \text{ is cognitive}\},
\end{equation}
where the maximum is over all hierarchical sequences of partitions
$(\pi_1, \ldots, \pi_k)$ and compression maps $(g_1, \ldots, g_k)$
satisfying the conditions of \cref{thm:exact-closure} at each level, subject
to the \emph{strict reduction} requirement $|S_{i+1}| < |S_i|$ at each
level~$i$ (i.e., the partition $\pi_i$ is non-trivial: at least one
group contains more than one component).  Since $|S|$ is finite, this
ensures $\delta(\mathcal{C}) \leq |S| - 1 < \infty$.
\end{definition}

The definition provides a
qualitative, non-anthropocentric ordering of intelligence without
requiring a binary threshold.\footnote{Illustrative ordinal
rankings: a hydrogen atom has depth~$\sim$1 (quantum constraint
resolution at the particle level); a bacterium $\sim$3--4
(molecular, metabolic, behavioral); a human brain $\sim$6--8
(ionic, synaptic, columnar, areal, network, behavioral, social).
These estimates are based on empirically identifiable
organizational levels and should not be read as precise
measurements; see \cref{rem:depth-computability}.}


% ==========================================================================
\section{Physical Instantiations of DCR}\label{sec:physics}
% ==========================================================================

We now exhibit structural witnesses that fundamental physical processes
instantiate the DCR triad, supporting the claim that the cosmos is
cognitive at every scale.  For each example, we identify the five DCR
ingredients using the following checklist:

\begin{enumerate}[nosep,label=(\roman*)]
  \item \emph{Components \& degrees of freedom} --- what are the
    interacting parts and their local state spaces?
  \item \emph{Constraints} --- what local compatibility conditions
    (conservation laws, fitness, synaptic weights) couple neighboring
    components?
  \item \emph{Exploration} --- what mechanism generates variability
    across the configuration space (quantum fluctuations, mutation,
    stochastic firing)?
  \item \emph{Resolution} --- how do local interactions reduce
    constraint violation without global coordination?
  \item \emph{Stable coherent attractor} --- what is the coherent
    macroscopic pattern that emerges (completed transaction, convection
    roll, adapted species, neural representation)?
\end{enumerate}

\noindent
\Cref{ex:benard} carries out a detailed verification sketch
(conditions \ref{cond:minorization}--\ref{cond:coherence}) for
thermodynamic self-organization (see \cref{rem:benard-caveat} for
caveats on the proof-sketch character); the remaining examples are
presented at the level of structural mappings, with a remark
(\cref{ex:benard}, following) on how the same verification
template applies.

\subsection{Quantum Mechanics}\label{ssec:quantum}

Consider a system of $N$ interacting quantum particles (or field modes).
The standard decoherence account \citep{zurek2003decoherence} treats
the suppression of off-diagonal coherences as the mechanism by which
classical reality emerges, but decoherence alone never yields a definite
outcome---it produces an improper mixture, not a selected event. The DCR
structure of quantum mechanics is most transparently exhibited by the
\emph{Transactional Interpretation} (TIQM)
\citep{cramer1986transactional}, which builds on the Wheeler--Feynman
absorber theory \citep{wheeler1945interaction}. In TIQM, every quantum
event is a \emph{transaction}---a completed handshake between emitter and
absorber mediated by retarded (offer) and advanced (confirmation) waves.
We use TIQM as a \emph{structural witness} that quantum dynamics can be
read as a distributed constraint-resolution process; DCR does not require
endorsing any particular interpretation of quantum mechanics, and no
claim is made that DCR solves or dissolves the measurement problem.
A second, interpretation-neutral witness based on decoherence and
einselection is given in \cref{rem:interpretation-independence}.
The TIQM mapping onto the DCR triad is as follows:

\begin{itemize}[nosep]
  \item \textbf{Components:} Emitter and absorber sites---the vertices of
        the spacetime interaction graph.
  \item \textbf{Degrees of freedom:} The possible quantum states (energy,
        momentum, polarization, spin) at each site, drawn from the local
        Hilbert space $\mathcal{H}_s$.
  \item \textbf{Exploration:} The \emph{offer wave} $\psi$ (retarded wave)
        propagates from the emitter to all potential absorbers, exploring
        every possible transaction partner simultaneously. In the Feynman
        path integral formulation \citep{feynman1948space}, this is the sum
        over all paths weighted by $e^{iS/\hbar}$---the emitter explores the
        entire accessible configuration space.
  \item \textbf{Constraints:} Conservation laws (energy, momentum, angular
        momentum, charge) at each interaction vertex. For an edge
        $\{s,s'\}$ in the interaction graph, the constraint $R_{\{s,s'\}}$
        requires that the quantum numbers carried by the offer wave from
        emitter $s$ match those that absorber $s'$ can accept, given $s'$'s
        own state and the applicable conservation laws.
  \item \textbf{Resolution:} The \emph{confirmation wave} $\psi^*$ (advanced
        wave) propagates from each potential absorber back to the emitter.
        The Wheeler--Feynman handshake is distributed constraint resolution:
        each absorber independently evaluates the offer against its local
        constraints and responds; the transaction that forms is the one
        where all constraints are simultaneously satisfied across both
        endpoints. There is no central selector choosing the outcome---the
        definite result emerges from the mutual satisfaction of local
        conservation laws, distributed across spacetime.
  \item \textbf{Stable pattern:} The \emph{completed transaction}---a
        definite, irreversible transfer of conserved quantities between
        emitter and absorber. Once formed, the transaction is a classical
        fact: the stable coherent attractor of the handshake process.
\end{itemize}

The retrocausal structure is not a defect but a feature: constraints
propagate both forward and backward in time, making the resolution
genuinely distributed across spacetime rather than confined to a single
time-slice. What is conventionally called ``wavefunction collapse''
can be viewed, as a structural witness, as the convergence of a
distributed constraint satisfaction process to its feasible
solution---without implying a solution to the outcome-selection
problem.


For $N$ interacting particles, the interaction graph $G$ has particles as
vertices and pairwise interactions as edges. Each interaction is a
potential transaction site where conservation constraints must be locally
satisfied. The global physical outcome---the set of completed
transactions---is the configuration $\omega \in \mathcal{F}$ where all
local constraints are simultaneously met: the feasible set of the
constraint network, reached by distributed resolution without global
coordination.

\begin{remark}[Selection and collapse]
Quantum collapse and constraint-mediated selection
(\cref{rem:constraint-mediated-selection}) share the abstract
template: variation $\to$ constraint filtering $\to$ retention.
In both cases, multiple possibilities are explored (superposition /
genetic variation), constraints select which possibilities are realized
(conservation laws / fitness landscape), and the selection is local and
distributed (each absorber / each organism evaluates constraints
independently).  We reserve ``natural selection'' for the biological,
inheritance-based instance; the shared structure is the DCR triad,
differing only in the physical substrate and timescale.
\end{remark}





\subsection{Thermodynamic Self-Organization}\label{ssec:thermo}

We model Rayleigh--B{\'e}nard convection as a DCR-system under a
standard lattice discretization, illustrating how the DCR axioms
map onto a concrete physical system.  The verification is a
sketch, not a full proof (see \cref{rem:benard-caveat}).

Consider a fluid layer between horizontal plates, heated from below
($T_H$) and cooled from above ($T_C$), in the Boussinesq approximation
\citep{chandrasekhar1961hydrodynamic}. We discretize the fluid domain on a
regular $d$-dimensional lattice with $N$ parcels and spacing $h$.

\begin{example}[B{\'e}nard Convection as a Cognitive System]%
\label{ex:benard}
We claim that for Rayleigh number
$\mathrm{Ra} > \mathrm{Ra}_c$ (above the convective instability
threshold), the stochastic lattice Boussinesq system with thermal
fluctuations constitutes a cognitive system
$\mathcal{C} = (\mathcal{N}, \{X_t\}, R, \mathcal{A})$ in the
sense of \cref{def:dcr-system}, under the following standard
assumptions: (i)~the finite-difference discretization preserves the
energy dissipation structure of the continuous Boussinesq equations,
(ii)~the spectral gap $\lambda_1$ of the graph Laplacian on the
lattice is positive, and (iii)~the Gaussian noise amplitude
$\sigma > 0$ is fixed.
\end{example}

\begin{proof}[Verification sketch]
We construct the DCR tuple and verify the general state-space conditions
\ref{gen:drift}--\ref{gen:full-support} of \cref{app:general};
see \cref{rem:benard-caveat} for caveats on the level of rigor.

\textbf{Constraint network.}
Let $S = \{1,\ldots,N\}$ index the parcels, with state space
$D_s = [-v_{\max}, v_{\max}]^d \times [T_C, T_H]$ for each $s$
(velocity and temperature, bounded by the energy balance). The
configuration space $\Omega = \prod_s D_s$ is compact. The interaction
graph $G$ is lattice adjacency (connected for $N \geq 2$). For each edge
$e = \{s,s'\} \in E$, the constraint relation $R_e$ encodes the
discretized Boussinesq conservation laws at the interface:
$(\omega_s, \omega_{s'}) \in R_e$ iff the discrete incompressibility
condition $\nabla^h_{ss'} \cdot \mathbf{v} = 0$, the discrete momentum
balance
$\nu\,\nabla^{h,2}_{ss'}\mathbf{v}
 - (\mathbf{v}\cdot\nabla^h_{ss'})\mathbf{v}
 + \beta(T-T_{\mathrm{ref}})\mathbf{g}
 = \nabla^h_{ss'} p$,
and the discrete energy balance
$\kappa\,\nabla^{h,2}_{ss'}T
 = (\mathbf{v}\cdot\nabla^h_{ss'})T$
are satisfied at the $\{s,s'\}$ interface, where $\nabla^h_{ss'}$ and
$\nabla^{h,2}_{ss'}$ denote the standard finite-difference gradient and
Laplacian operators, $\nu$ is kinematic viscosity, $\kappa$ is thermal
diffusivity, $\beta$ is the thermal expansion coefficient, and
$\mathbf{g}$ is gravitational acceleration.

\textbf{Violation.}
The pairwise violation $v_e(\omega_s, \omega_{s'})$ is the sum of squared
residuals of the three conservation equations at the $\{s,s'\}$ interface.
Then $v_e \geq 0$ with equality iff the steady-state Boussinesq equations
are locally satisfied, and $\Viol$ is continuous on compact $\Omega$.

\textbf{Dynamics.}
The resolution kernel $R$ is a semi-implicit Gauss--Seidel sweep of the
discretized Boussinesq equations: each parcel updates its velocity and
temperature using only the current states of its lattice neighbors,
satisfying the locality requirement of \cref{eq:monotone}. The
exploration kernel $E$ adds Gaussian noise of variance
$\sigma^2 \propto k_B T_{\mathrm{ref}}/(\rho\, h^d)$ (fluctuating
hydrodynamics), projected onto $\Omega$:
\[
  E(\omega, \cdot) = \mathrm{Law}\!\bigl(
    \Pi_\Omega(\omega + \sigma\,\boldsymbol{\xi})\bigr),
  \qquad \boldsymbol{\xi} \sim \mathcal{N}(0, I_{N(d+1)}).
\]

\textbf{Verification of conditions.}
\begin{enumerate}[nosep,label=(\alph*)]
  \item \emph{Foster--Lyapunov drift.} The energy functional
    $\mathcal{E}(\omega) = \sum_s\bigl[\tfrac{1}{2}|\mathbf{v}_s|^2
    + \tfrac{1}{2}|T_s - T_{\mathrm{lin},s}|^2\bigr]$
    (where $T_{\mathrm{lin}}$ is the linear conduction profile) satisfies
    \[
      \mathcal{E}(\omega^{(t+1)}) \leq \mathcal{E}(\omega^{(t)})
      - \Delta t\bigl[\nu\,\lVert\nabla^h\mathbf{v}\rVert^2
      + \kappa\,\lVert\nabla^h\theta\rVert^2\bigr]
      + \Delta t\,\mathrm{Ra}\,(\theta, v_z)
    \]
    under the resolution step, where $\theta = T - T_{\mathrm{lin}}$.
    By the discrete Poincar{\'e} inequality
    ($\lVert\nabla^h u\rVert^2 \geq \lambda_1\lVert u\rVert^2$ with
    $\lambda_1 > 0$ the spectral gap of the graph Laplacian), the
    dissipative terms dominate the buoyancy source outside a compact
    neighborhood $C$ of the convection roll attractor, yielding a
    Foster--Lyapunov drift condition
    (\cref{rem:drift-sufficient}) for $L = \Viol + 1$ with small
    set $C$.  (The transfer from $\mathcal{E}$ to $\Viol$ near the
    attractor follows from the comparability of the respective
    Hessians under the linearized Boussinesq operator---a standard
    result in the stability theory of discretized
    Navier--Stokes systems.)
  \item \emph{$\varphi$-irreducibility.} The Gaussian kernel $E$ has
    positive density on $\mathrm{int}(\Omega)$, so
    $K(\omega,A) \geq \epsilon\,E(\omega,A) > 0$ for any $A$ with
    positive Lebesgue measure $\lambda(A) > 0$. The chain is
    $\lambda$-irreducible.
  \item \emph{Minorization.} Choose $c$ large enough that
    the sublevel set
    $C = \{\omega \in \mathrm{int}(\Omega) : \Viol(\omega) \leq c\}$
    is visited infinitely often under the drift
    (condition~\ref{gen:drift}).  Since $C$ is compactly contained
    in the interior of $\Omega$, the (unprojected) Gaussian
    exploration density is bounded below by some $\delta > 0$ on
    $C \times C$.  Hence
    $K(\omega, A) \geq \epsilon\,\delta\,\lambda(A \cap C)$ for
    $\omega \in C$, establishing the minorization
    condition~\ref{gen:minorization} with
    $\nu = \lambda(\cdot \cap C)/\lambda(C)$.  (The boundary of
    $\Omega$, where the projection $\Pi_\Omega$ distorts densities,
    is avoided by taking $C \subset \mathrm{int}(\Omega)$; see
    \cref{rem:benard-caveat}.)
  \item \emph{Weak Feller.} The Boussinesq update is polynomial in
    $\omega$ and neighbor states (hence continuous); the Gaussian density
    is smooth. Their convex combination $K$ is weak Feller.
  \item \emph{Full exploration support.} The Lebesgue-equivalent
    irreducibility measure charges every open set, in particular those
    meeting $\mathcal{F}$.
\end{enumerate}

\textbf{Attractor and coherence.}
For $\mathrm{Ra} > \mathrm{Ra}_c$, the feasible set $\mathcal{F}$
(steady-state solutions of the discretized Boussinesq equations) includes
the convection roll patterns \citep{cross1993pattern}. The
Gauss--Seidel update of parcel~$s$ makes
$(\mathbf{v}_s^{(t+1)}, T_s^{(t+1)})$ depend on the states of
neighbors~$s'$ through the discretized momentum and energy equations,
so the unique $\mu_\epsilon$ has non-product $(s,s')$-marginals.
By \cref{thm:convergence}, the chain converges to a unique
$\mu_\epsilon$ with $\Coh_E(\mu_\epsilon) > 0$, and the
convection rolls constitute the stable coherent attractor $\mathcal{A}$.
\end{proof}

The convection pattern is \emph{not} at equilibrium (DCR correctly
excludes equilibrium), and it arises without any central controller
selecting the pattern. It is a cognitive system of depth~1.




\subsection{Biological Adaptation}\label{ssec:biology}

\begin{itemize}[nosep]
  \item \textbf{Components:} Organisms in a population.
  \item \textbf{Degrees of freedom:} Genotype/phenotype space.
  \item \textbf{Exploration:} Mutation, recombination, developmental noise.
  \item \textbf{Constraints:} Environmental fitness landscape, inter-organism
        competition, predator--prey relations.
  \item \textbf{Resolution:} Natural selection propagates constraints locally
        (each organism's survival depends on its local fitness, not a global
        optimization). This is inherently distributed.
  \item \textbf{Stable pattern:} Adapted species occupying fitness peaks---the
        coherent attractor of the evolutionary dynamics
        \citep{kauffman1993origins}.
\end{itemize}

Biological evolution is a cognitive system of depth $\geq 2$: the organisms
themselves are cognitive systems (metabolic constraint resolution), and the
population-level dynamics is a second layer of cognition.

\subsection{Neural Cognition}\label{ssec:neural}

\begin{itemize}[nosep]
  \item \textbf{Components:} Neurons (or neural populations).
  \item \textbf{Degrees of freedom:} Firing rates, membrane potentials,
        synaptic states.
  \item \textbf{Exploration:} Spontaneous activity, noise, stochastic
        neurotransmitter release.
  \item \textbf{Constraints:} Synaptic weights, lateral inhibition, top-down
        priors encoded in connectivity.
  \item \textbf{Resolution:} Local integration-and-fire dynamics; each neuron
        resolves its inputs against its threshold. Constraint propagation is
        distributed across the network.
  \item \textbf{Stable pattern:} Perceptual representations, motor plans,
        decisions---coherent attractors of the neural dynamics
        \citep{seth2021being}.
\end{itemize}

Neural cognition achieves high depth because the components (neurons) are
themselves biochemical cognitive systems, embedded in circuits that form
cognitive systems, embedded in areas, and so on up to whole-brain dynamics.

% ==========================================================================
\section{Recovery of Existing Frameworks}\label{sec:recovery}
% ==========================================================================

\subsection{Free Energy Principle as a Special Case}\label{ssec:fep-recovery}

\begin{proposition}[FEP Recovery]\label{prop:fep}
The Free Energy Principle is a special case of DCR obtained when:
\begin{enumerate}[nosep]
  \item The constraint network is bipartite, partitioned into ``internal''
        and ``external'' components with a Markov blanket boundary.
  \item The constraints encode a generative model
        $p(\tilde{s}, \psi \mid m)$ relating external causes $\psi$ to
        sensory observations $\tilde{s}$.
  \item The \emph{stabilization criterion} uses variational free energy
        $F$ as the Lyapunov functional (in place of $\Viol + 1$).
        Note that $-F$ does not play the same mathematical role as
        $\Coh$: it is not nonnegative and does not vanish on product
        measures.  The analogy is functional (both witness
        ``convergence to an attractor''), not structural.
  \item The resolution dynamics is gradient descent on $F$
        (recognition dynamics).
\end{enumerate}
Under these specializations, DCR's ``explore--resolve--stabilize'' reduces to
FEP's ``prediction error minimization via active inference.''
\end{proposition}

\begin{proof}
We construct an explicit embedding of the FEP formalism into DCR.

\textbf{Step 1: Constraint network.}
Let $S = S_\mu \cup S_b \cup S_\eta$ be the decomposition into internal
($\mu$), blanket ($b$), and external ($\eta$) states. The Markov blanket
condition means $E$ contains no edges between $S_\mu$ and $S_\eta$ directly;
all coupling is mediated through $S_b$. This is a constraint network with
$G$ having the bipartite-through-blanket structure.

Define the constraint relations on blanket--internal edges via the generative
model: for $s \in S_\mu$, $s' \in S_b$,
\[
  R_{\{s,s'\}} = \{(\mu_s, b_{s'}) :
  p(\tilde{s}_{s'} \mid \mu_s) > 0\},
\]
encoding which internal states are consistent with which sensory observations.

\textbf{Step 2: Violation as surprise.}
Assume the generative model satisfies
$p(\tilde{s}_{s'} \mid \mu_s) > 0$ for all $(\mu_s, \tilde{s}_{s'})$
in the model's support (this ensures finite violations; models that
assign zero probability to observable events are degenerate).
The constraint violation functions are:
\[
  v_{\{s,s'\}}(\mu_s, b_{s'}) = -\ln p(\tilde{s}_{s'} \mid \mu_s).
\]
The total violation is then
$\Viol(\omega) = -\sum_{\{s,s'\}} \ln p(\tilde{s}_{s'} \mid \mu_s)$,
which is finite under the positivity assumption.
Note that $\Viol = 0$ requires $p(\tilde{s}_{s'} \mid \mu_s) = 1$
for all blanket components, which is generically impossible in
non-degenerate probabilistic models; accordingly, we use the
soft-constraint reading (\cref{def:violation}), where the
feasible set is $\mathcal{F} = \arg\min V$ (the
internal states that best predict the observations).

To connect this to the FEP's surprisal $-\ln p(\tilde{s} \mid \mu)$, we
assume the generative model factorizes over blanket components conditioned
on internal states:
$p(\tilde{s} \mid \mu) = \prod_{s'} p(\tilde{s}_{s'} \mid \mu_{s(s')})$,
where $s(s')$ denotes the internal component coupled to blanket component
$s'$. Under this \emph{conditional independence} assumption (standard in
mean-field formulations of FEP), the sum reduces to:
$\Viol(\omega) = -\ln \prod_{s'} p(\tilde{s}_{s'} \mid \mu_{s(s')})
= -\ln p(\tilde{s} \mid \mu)$---the surprisal.

The variational free energy $F = \mathbb{E}_q[-\ln p(\tilde{s}, \psi)] +
\mathbb{E}_q[\ln q(\psi)]$ satisfies $F \geq -\ln p(\tilde{s})$ (by the
non-negativity of KL divergence), so $F$ is an upper bound on the surprisal,
hence on $\Viol$.

\textbf{Step 3: Resolution as free energy minimization.}
The FEP's recognition dynamics---gradient descent on $F$ with respect to
internal parameters---is a local update rule: each internal state $\mu_s$
adjusts based on its blanket neighbors.  In the FEP specialization, the
natural Lyapunov function is $F$ itself (rather than $\Viol + 1$):
gradient descent on a smooth function bounded below yields
$\mathbb{E}[F_{t+1}] \leq F_t - \alpha \|\nabla F\|^2$ for suitable
step size.  Since $F$ is bounded below and its sublevel sets are
compact (under standard regularity of the generative model), $F$
satisfies the Foster--Lyapunov drift condition~\ref{gen:drift} for
the combined recognition-plus-exploration kernel.  (Note that
$\Viol \leq F$ does \emph{not} by itself imply that descent on $F$
reduces $\Viol$; rather, $F$ serves as a valid Lyapunov function in
its own right, and concentration near low-$F$ regions entails
concentration near low-$\Viol$ regions via the bound.)

\textbf{Step 4: Exploration as active inference.}
FEP's active inference includes epistemic actions---perturbations to blanket
states that sample the environment. These provide the exploration kernel $E$:
the system probes configurations that might reduce uncertainty, ensuring
accessibility of low-violation regions.

\textbf{Step 5: Attractor.}
The attracting set under FEP is the set of internal states where
$F$ is minimized, i.e., $q(\psi) \approx p(\psi \mid \tilde{s})$. This is
a feasible configuration (minimal violation) and is coherent since internal
states are statistically coupled through the shared generative model.

Hence the FEP system $(\{S_\mu, S_b, S_\eta\},$ bipartite $G$, recognition
dynamics, epistemic exploration$)$ is a DCR cognitive system under the
specializations stated.
\end{proof}

DCR is strictly more general than FEP in two ways: (1)~it does not require
a bipartite structure with a Markov blanket, and (2)~it does not require
the constraints to be expressible as a generative model. Physical constraint
resolution (e.g., decoherence, convection) need not involve
``inference'' in any Bayesian sense.

\subsection{Integrated Information Theory as a Special Case}\label{ssec:iit-recovery}

\begin{proposition}[IIT Recovery]\label{prop:iit}
The integrated information $\Phi$ of IIT~2.0
\citep{tononi2004information} is recoverable from DCR's coherence measure
under the following specializations:
\begin{enumerate}[nosep]
  \item The constraint network encodes the transition probability matrix
        (TPM) of IIT: for each edge $\{s, s'\}$, the constraint $R_{\{s,s'\}}$
        encodes which state transitions of $s$ are compatible with the current
        state of $s'$.
  \item The analysis is restricted to a single time step (the TPM acts once).
  \item Coherence is refined to its irreducible component via the minimum
        information partition (MIP).
\end{enumerate}
\end{proposition}

\begin{proof}
\textbf{Step 1: From DCR coherence to total correlation.}
DCR's coherence measure (\cref{def:coherence}) is the edge-sum mutual
information $\Coh_E(\mu) = \sum_{\{s,s'\} \in E} I_\mu(X_s; X_{s'})$.
For the connection to IIT, we pass to the \emph{multi-information}
(total correlation)
$\Coh(\mu) := D_{\mathrm{KL}}(\mu \,\|\, \bigotimes_s \mu_s)$,
which upper-bounds $\Coh_E$ and quantifies the total statistical
dependence among all components.  In particular,
$\Coh_E(\mu) > 0 \Rightarrow \Coh(\mu) > 0$.

\textbf{Step 2: From total correlation to integrated information.}
IIT~2.0 defines $\Phi$ using KL divergence as follows. For a system in
state $x$ with TPM $T$, let $\mu_x = p(X_{t+1} \mid X_t = x)$ be the
one-step conditional distribution over successor states. For a bipartition
$\pi$ that cuts $S$ into parts $A$ and $B$, define the partitioned
distribution $p_\pi(X_{t+1} \mid x) = p(X^A_{t+1} \mid x) \otimes
p(X^B_{t+1} \mid x)$, which severs all inter-part dependencies. Then:
\[
  \Phi(x) = \min_{\pi \in \mathcal{P}}
  D_{\mathrm{KL}}\!\bigl(\mu_x \;\|\; p_\pi(\cdot \mid x)\bigr),
\]
where $\mathcal{P}$ is the set of bipartitions. Since
$D_{\mathrm{KL}}(\mu_x \| \bigotimes_s (\mu_x)_s) = \Coh(\mu_x)$ and
$D_{\mathrm{KL}}(\mu_x \| p_\pi(\cdot \mid x))$ measures only the
inter-part dependence (the intra-part dependencies within $A$ and $B$
cancel), we obtain:
\[
  \Phi(x) = \min_{\pi \in \mathcal{P}} \bigl[
    \Coh(\mu_x) - \Coh_A(\mu_x) - \Coh_B(\mu_x)
  \bigr],
\]
where $\Coh_A, \Coh_B$ denote the multi-information within each part.
That is, $\Phi$ extracts the \emph{irreducible} component of DCR's
coherence---the inter-part dependence that survives every possible
bipartition.

\textbf{Step 3: Static vs.\ dynamic.}
IIT computes $\Phi$ at a single time step. DCR's coherence is defined on
the stationary distribution $\mu^*$, which integrates over the full
dynamical trajectory. The IIT measure is recovered by restricting $\mu$
to the conditional distribution at a single step.

Hence $\Phi$ is a refinement of $\Coh$: it subtracts the reducible
component. DCR's $\Coh > 0$ is necessary for $\Phi > 0$ (since $\Phi \leq
\Coh$), but $\Coh > 0$ does not imply $\Phi > 0$ (a system can have
statistical dependencies that are fully decomposable). In this sense, IIT
imposes a \emph{stricter} coherence criterion than DCR's default measure.
\end{proof}


DCR extends IIT in two directions: (1)~it provides a \emph{process-level}
account of how coherence arises through exploration and resolution, rather
than merely measuring it at a single time step; and (2)~it defines cognition
for systems where $\Phi$ is intractable (the computation is
$O(2^n)$) but the DCR triad---exploration, resolution, convergence to
coherent attractors---is empirically observable.

% ==========================================================================
\section{Predictions and Falsifiability}\label{sec:predictions}
% ==========================================================================

A framework that explains everything predicts nothing. DCR makes the following
falsifiable claims:

\begin{enumerate}
  \item \textbf{Coherence--exploration tradeoff.} In any cognitive system,
        there exists an optimal regime where exploration rate and constraint
        strength are balanced. Too much exploration (relative to constraint
        strength) yields incoherent dynamics; too much constraint yields
        rigid, brittle systems that fail to adapt. This predicts a universal
        inverted-U relationship between exploration rate and cognitive
        performance, testable in neural systems (cf.\ stochastic
        resonance \citep{gammaitoni1998stochastic}), evolutionary
        simulations, and optimization algorithms.

  \item \textbf{Depth predicts adaptability.} Systems with greater cognitive
        depth $\delta$ (\cref{def:depth}) should exhibit greater adaptability
        to novel environments, because deeper nesting provides more levels at
        which exploration--resolution can occur. This is testable: compare the
        adaptability of systems with different organizational depths (e.g.,
        single-celled vs.\ multicellular organisms, shallow vs.\ deep neural
        networks, flat vs.\ hierarchical organizations).

  \item \textbf{Critical constraint density.} There exists a critical density
        of constraints $|E|/|S|$ below which the system cannot sustain coherent
        attractors and above which the system becomes rigid. This parallels the
        satisfiability phase transition in random constraint satisfaction
        problems \citep{mezard2002random}, where a sharp transition from
        under-constrained (many solutions, low coherence) to over-constrained
        (no solutions, frozen dynamics) occurs at a critical clause-to-variable
        ratio. DCR predicts that this transition coincides with maximal
        cognitive capacity: near the critical point, the system exhibits
        signatures of self-organized criticality \citep{bak1987self}---power-law
        distributions of attractor sizes, long-range correlations, and maximal
        susceptibility. The novel prediction beyond the SAT literature is that
        this critical regime should also maximize coherence $\Coh_E(\mu_\epsilon)$
        and support the deepest cognitive nesting $\delta$. This is testable
        in constraint satisfaction problems and neural network models.

  \item \textbf{Coarse-graining preserves cognitive signatures.} If DCR is
        correct, then empirically measured coherence, exploration rates, and
        convergence timescales should obey scaling laws across levels of
        description of the same system (e.g., single-neuron vs.\ population
        vs.\ whole-brain dynamics). Specifically, the ratio of exploration
        timescale to resolution timescale should be approximately preserved
        under coarse-graining.

  \item \textbf{Transaction-density gradients and inertial analogues
        (speculative).}
        In substrate models where ``exploration'' is mediated by a sea
        of uncollapsed potential interactions (transactions),
        accelerated motion can induce anisotropies in the accessible
        interaction field (via horizon-like cutoffs), producing
        effective resistance-to-acceleration terms and mutual
        ``shielding'' effects between nearby bodies.  DCR does not
        assume this mechanism, but if such a substrate description is
        correct then controlled simulations should exhibit
        acceleration-dependent force terms that scale with the induced
        interaction anisotropy and with transaction-density gradients.
        This would provide a concrete route to testing whether certain
        gravitational/inertial phenomena can be re-expressed as
        emergent constraint-resolution effects.
\end{enumerate}

\noindent
We elevate the transactional-density mechanism to an explicit
conjecture:

\medskip
\noindent\fbox{\parbox{0.95\textwidth}{%
\textbf{Conjecture (Gravity and inertia from transaction-density
gradients).}
Let $\rho_\tau(\mathbf{x})$ denote the local transactional density
(completed constraint-satisfying couplings per unit volume per unit
time) in a DCR substrate.  Two bodies mutually shield the
transaction field along their connecting axis, producing a
$\rho_\tau$-gradient and hence a net drift toward each other; an
accelerating body creates a horizon-like cutoff behind it,
producing a $\rho_\tau$-anisotropy opposing acceleration.  If
gravity and inertia admit such a reformulation, then (i)~the
gravitational ``constant'' is a derived function of the ambient
$\rho_\tau$, and (ii)~inertial mass equals the integrated
$\rho_\tau$-anisotropy at fixed acceleration.  This is speculative
and untested; we record it because it illustrates how far the
DCR+optimization reading might extend, and because it generates
concrete simulation targets.}}
\medskip

% ==========================================================================
\section{Discussion}\label{sec:discussion}
% ==========================================================================

\subsection{The Cosmos as Cognitive}

If DCR is correct, then cognition is not an emergent property of brains---it is
what physics \emph{does}. The offer wave explores all possible absorbers; the
Wheeler--Feynman handshake resolves conservation constraints; the completed
transaction stabilizes into a classical fact. Thermal fluctuations explore the
space of flow configurations; the Navier--Stokes equations resolve constraints
locally between neighboring parcels; convection rolls stabilize. Mutation
explores genotype space; natural selection resolves fitness constraints;
adapted species stabilize. The same formal process, recurring at every
scale, connected by the coarse-graining construction.

The TIQM framing (\cref{ssec:quantum}) reveals a further unity: what physics
calls ``collapse'' and what biology calls ``selection'' are both instances
of constraint-mediated selection (\cref{rem:constraint-mediated-selection}):
multiple possibilities are explored, distributed constraints determine
which are realized, and a stable outcome is retained. The retrocausal structure of the transactional interpretation
suggests that constraint resolution need not respect the arrow of time;
it is a relation among boundary conditions, not a process confined to one
temporal direction.

A single motif unifies the three engineering/physical witnesses
discussed earlier---distributed consensus
(\cref{rem:consensus-witness}), quantum transactions
(\cref{ssec:quantum}), and machine-learning self-play
(\cref{sec:discussion}, \emph{Self-play as engineered DCR}): in
all three, global stabilization arises from local compatibility
constraints under partial, delayed information.  No central
controller possesses the full constraint set at any instant; yet the
system converges to a coherent outcome because local
violation-reducing steps compose into a globally directed drift
(\cref{thm:convergence}).

The discrete ontic model of \citet{powers2024statistical} lends additional
support to this picture.  If quantum probabilities arise from counting
admissible configurations of binary sequences---\emph{micro-choices} at
the level of symbol orderings---then what physics calls a ``quantum state''
is already a coarse-grained summary of a discrete constraint resolution
process (\cref{rem:micro-choices}).  The continuum of Hilbert space is
recovered only in the limit $n \to \infty$; at every finite scale the
system is a finite constraint network undergoing exploration, resolution,
and stabilization.  This dissolves the objection that DCR's discrete
formalism cannot capture continuous physics: the continuity is emergent,
not fundamental.

This is not panpsychism in the traditional sense. We do not claim that an
emitter--absorber pair ``has experiences.'' We claim that the transaction
by which a photon is emitted and absorbed is \emph{the same kind of
process} as the one by which a neuron participates in perception---formally,
structurally the same, as verified through the explicit construction in
\cref{ex:benard} and the structural mappings of
\cref{ssec:quantum,ssec:biology,ssec:neural}. ``Cognition'' is the name we
give to this process. Whether one wishes to call this ``experience'' at the
quantum level is a separate philosophical question that DCR does not
adjudicate.


\subsection{Relationship to Process Philosophy}

DCR exhibits structural resonances---not evidential dependencies---with
Whitehead's process philosophy \citep{whitehead1929process}, which held
that reality consists not of substances but of ``actual occasions'':
events of experience that ``prehend'' (take account of) their environment
and ``concresce'' into definite outcomes.  The correspondence is
suggestive: prehension maps onto exploration of degrees of freedom under
constraints imposed by neighboring occasions, and concrescence maps onto
resolution into a coherent, stabilized pattern.  We note these parallels
as interpretive context, not as independent support for DCR's formal
claims.

The TIQM framing sharpens the correspondence.  A Wheeler--Feynman
transaction---a discrete event in which multiple possibilities are
explored (the offer wave), constraints are propagated bidirectionally
(the confirmation wave), and a definite outcome concresces (the completed
transaction)---mirrors Whitehead's insistence that actual occasions are
constituted by their relations to both past and future, not built up
sequentially.  Whether this structural parallel reflects a deeper
ontological identity or merely a shared mathematical pattern is a
question DCR does not settle; we observe only that process ontology and
DCR converge on the same picture of reality as constituted by events of
constraint resolution rather than by persistent substances.

\subsection{Relation to Neural-Network Universe Proposals}

Vanchurin's ``world as a neural network'' program
\citep{vanchurin2020world} is the closest existing proposal to DCR in
ambition: it posits that the universe is fundamentally a learning
system and derives Schr\"odinger/Madelung-like and
Einstein--Hilbert-like effective forms from network update rules under
specific assumptions (see \cref{rem:nn-universe} for a summary).  The
key structural overlap is the two-tier dynamics---trainable variables
evolving on a slow timescale and hidden neuron states on a fast
timescale---which maps directly onto DCR's timescale separation
between inter-group and intra-group dynamics
(\cref{def:timescale}).  Vanchurin's ``second law of learning''
(entropy production from stochasticity vs.\ entropy destruction from
learning) is a special case of DCR's exploration--resolution balance:
stochastic updates inject variability; learning rules reduce
constraint violation; stable effective laws emerge at the balance
point.

The differences are instructive.  Vanchurin's proposal is
\emph{substrate-specific}: it commits to the universe being literally
a neural network, with particular thermodynamic and Onsager-symmetry
assumptions driving the recovery of known physics.  DCR is
\emph{substrate-agnostic}: it identifies the process
(explore--resolve--stabilize) without specifying what implements it.
A neural-network universe is one possible microphysics whose effective
behavior instantiates the DCR triad; other microphysics (discrete
ontic models \citep{powers2024statistical}, spin networks, causal
sets) could equally serve.  In this sense, DCR provides the
\emph{process-level} explanation of \emph{why} a neural-network
universe would produce stable macroscopic laws: because it implements
distributed constraint resolution, and DCR dynamics converge to
coherent attractors under generic conditions
(\cref{thm:convergence}).

\subsection{Implications for Artificial Intelligence}

Current AI systems (large language models, reinforcement learning agents)
implement the DCR triad in restricted form: stochastic sampling (exploration),
gradient descent or constraint propagation (resolution), convergence to
low-loss configurations (stabilization). DCR predicts that the ``intelligence''
of these systems is bounded by their cognitive depth: the number of nested
levels at which the explore--resolve--stabilize cycle operates simultaneously.
This suggests that advances in AI may come not from scaling individual layers
but from increasing organizational depth---more levels of nested constraint
resolution.

\paragraph{Self-play as engineered DCR.}
Self-play systems in modern machine learning provide an engineered
instance of the DCR triad: parallel rollouts implement exploration;
selection and credit-assignment propagate constraints; and training
converges to stable policy attractors.  From a DCR perspective, the
apparent ``retroactive'' assignment of credit to earlier moves is a
benign analogue of retrocausal selection
(\cref{rem:collapse-selection}): later outcomes determine which
earlier degrees of freedom were effectively feasible given the
constraints.

\subsection{Limitations and Open Problems}

\begin{enumerate}
  \item \textbf{Timescale separation.} The closure theorem
        (\cref{thm:closure}) requires timescale separation between intra-group
        and inter-group dynamics. While this condition holds in many physical
        systems (atomic vs.\ molecular, synaptic vs.\ network), proving closure
        under weaker conditions---overlapping timescales, continuous-time
        limits, or stochastic timescale ratios---remains open. The convergence
        rates derived in \cref{lem:macro-drift} depend on the separation
        parameter $\eta$; quantifying this dependence precisely for specific
        physical systems is an important next step.

  \item \textbf{Quantitative predictions.} While DCR predicts qualitative
        relationships (inverted-U, depth--adaptability, critical constraint
        density), deriving precise quantitative predictions requires
        specifying the constraint structure of particular physical systems,
        which is a substantial empirical program.

  \item \textbf{The goal problem.} DCR defines goals as attractors of the
        dynamics, which avoids teleology. But this means that any attractor
        counts as a ``goal,'' including pathological ones (e.g., a dead
        organism is a stable attractor of biochemical dynamics). A richer
        notion of goal---perhaps involving the \emph{maintenance} of
        exploration capacity, connecting to autopoiesis---may be needed.

  \item \textbf{Temporal structure and retrocausality.} The TIQM framing
        of quantum DCR (\cref{ssec:quantum}) involves advanced waves
        propagating backward in time, suggesting that constraint resolution
        can be atemporal---a relation among boundary conditions rather than
        a process with a definite temporal direction. The current DCR
        formalism (\cref{sec:framework}) is built on forward-time Markov
        chains, which cannot accommodate retrocausal constraint propagation.
        Extending the framework to atemporal or bidirectional constraint
        resolution---perhaps using the two-state vector formalism or
        path-integral methods---is needed to fully capture the quantum case
        and may reveal a deeper temporal structure underlying the DCR triad.

  \item \textbf{Consciousness.} DCR is a theory of cognition, not of
        consciousness. It explains the process by which systems explore,
        resolve, and stabilize, but does not address the ``hard problem''
        \citep{chalmers1995facing} of why any of this is accompanied by
        subjective experience. DCR is compatible with, but does not entail,
        the identity of cognition and consciousness.
\end{enumerate}

% ==========================================================================
\section{Conclusion}\label{sec:conclusion}
% ==========================================================================

We have presented the Distributed Constraint Resolution (DCR) framework, a
formal, scale-free characterization of cognition as the process by which
components explore degrees of freedom and converge through distributed
constraint resolution into coherent, goal-stabilizing patterns. We have shown
that:

\begin{enumerate}[nosep]
  \item The framework is mathematically precise, built on constraint networks,
        stochastic dynamics, and information-theoretic coherence
        (\cref{sec:framework}).
  \item Under explicit timescale-separation and macro-sufficiency
        assumptions, the DCR form is stable under coarse-graining
        (conditional closure), providing a conditional composition
        scheme that reframes the combination problem and a natural
        measure of cognitive depth (\cref{sec:scale-free}).
  \item Fundamental physical processes satisfy the DCR axioms: as a
        detailed verification sketch for thermodynamic self-organization
        (\cref{ex:benard}), and structurally for quantum transactions,
        biological adaptation, and neural dynamics
        (\cref{sec:physics}). The quantum case, framed
        through the Transactional Interpretation, reveals that wavefunction
        collapse and biological selection share the same abstract
        template---constraint-mediated selection
        (\cref{rem:constraint-mediated-selection}). The discrete ontic model of
        \citet{powers2024statistical} provides independent evidence that
        quantum mechanics is compatible with---and may emerge from---the
        kind of finite combinatorial structure that DCR assumes
        (\cref{rem:micro-choices}); and \citet{vanchurin2020world}
        independently derives Schr\"odinger/Madelung-like and
        Einstein--Hilbert-like effective forms from a learning neural
        network, a substrate-specific instantiation of the DCR triad
        (\cref{rem:nn-universe}).
  \item The Free Energy Principle and Integrated Information Theory are
        recoverable as special cases (\cref{sec:recovery}).
  \item The framework makes falsifiable predictions about coherence--exploration
        tradeoffs, depth--adaptability relationships, and critical constraint
        densities (\cref{sec:predictions}).
\end{enumerate}

If DCR is correct, then cognition is not a biological accident but a
fundamental feature of physical reality---the process by which the universe
explores its own degrees of freedom and resolves into the coherent structures
we observe at every scale. The offer wave and the mutation, the handshake
and the selection, the transaction and the adapted species, the symbol
ordering and the quantum outcome: one process, many substrates.

\paragraph{Acknowledgments.}
The transactional-interpretation framing in \cref{ssec:quantum} was
sharpened by discussions of Ruth Kastner's Possibilist Transactional
Interpretation and its engineering analogues in distributed-ledger
consensus; we thank anonymous reviewers for pressing us to clarify
the interpretation-independence of the formal results.

\bigskip

% ==========================================================================
\appendix
% ==========================================================================

% ==========================================================================
\section{General State Spaces}\label{app:general}
% ==========================================================================

This appendix collects the full Foster--Lyapunov / Harris recurrence
machinery for DCR on general (possibly non-compact) state spaces.
The main text (\cref{sec:framework}) works exclusively with compact
$\Omega$ and Doeblin-type minorization; the results below extend to
non-compact Polish spaces at the cost of additional regularity
conditions.

\subsection{Combined DCR Dynamics --- General Version}\label{app:combined}

\begin{remark}[Why Meyn--Tweedie on compact spaces]\label{rem:meyn-tweedie}
On a compact state space~$\Omega$, existence of a stationary
distribution already follows from the Krylov--Bogoliubov theorem
(tightness is automatic), and one might wonder why one would invoke the
heavier Foster--Lyapunov / minorization / Harris recurrence apparatus
of \citet{meyn1993markov}.  Three reasons: (i)~the drift condition
provides \emph{quantitative} concentration bounds, not merely
existence; (ii)~minorization yields geometric convergence rates
(Theorem~15.0.1 of \citealp{meyn1993markov}), which inform the
timescale separation requirements in \cref{app:closure}; and
(iii)~the framework extends without modification to
non-compact~$\Omega$, which is needed for continuum limits
(\cref{rem:finiteness}) and for physical systems whose natural
state spaces are unbounded (e.g., momentum variables).
\end{remark}

For general (possibly non-compact Polish) state spaces, the combined
DCR dynamics requires the following conditions on the kernel
$K_\epsilon = (1-\epsilon)R + \epsilon\,E$:
\begin{enumerate}[nosep,label=(\alph*)]
  \item\label{gen:drift} \textbf{Foster--Lyapunov drift.}
    There exist constants $\lambda \in (0,1)$, $b < \infty$, and a
    measurable set $C \subseteq \Omega$ such that for the Lyapunov
    function $L(\omega) = \Viol(\omega) + 1$:
    \begin{equation}\label{gen:eq:drift}
      \int_\Omega L(\omega')\, K(\omega, d\omega') \leq
      \lambda\, L(\omega) + b\, \mathbf{1}_C(\omega).
    \end{equation}
  \item\label{gen:irreducibility} \textbf{$\varphi$-irreducibility.}
    There exists a probability measure $\varphi$ on $\Omega$ such that
    for all $\omega \in \Omega$ and all measurable $A$ with
    $\varphi(A) > 0$:
    $\sum_{n=1}^{\infty} K^n(\omega, A) > 0$.
  \item\label{gen:minorization} \textbf{Minorization on a small set.}
    There exist a measurable set $C \subseteq \Omega$,
    $\delta > 0$, and a probability measure $\nu$ on $\Omega$ such
    that $K(\omega, A) \geq \delta\, \nu(A)$ for all
    $\omega \in C$ and all measurable $A$.
  \item\label{gen:feller} \textbf{Weak Feller property.} For every
    bounded continuous $g : \Omega \to \mathbb{R}$, the map
    $\omega \mapsto \int g(\omega')\, K(\omega, d\omega')$ is continuous.
  \item\label{gen:full-support} \textbf{Full exploration support.} The
    irreducibility measure $\varphi$ satisfies $\varphi(U) > 0$ for every
    open set $U$ meeting the feasible set.
\end{enumerate}

\begin{remark}[Sufficient conditions for the drift]\label{rem:drift-sufficient}
A simple sufficient condition for~\ref{gen:drift} arises when the
resolution and exploration kernels satisfy separate bounds.  Suppose
there exist $\alpha > 0$ and $B < \infty$ such that
(i)~$\int \Viol(\omega')\,R(\omega,d\omega') \leq
(1-\alpha)\,\Viol(\omega)$ for all $\omega \notin \mathcal{F}$, and
(ii)~$\int \Viol(\omega')\,E(\omega,d\omega') \leq B$ for all
$\omega$.  Setting $\lambda = (1-\epsilon)(1-\alpha)$ and decomposing
$K = (1-\epsilon)R + \epsilon E$ gives the drift
condition~\ref{gen:drift} with $b = 1-\lambda+\epsilon B$ and
$C = \{\omega : \Viol(\omega) \leq b/(1-\lambda)\}$.
On compact~$\Omega$, condition~(ii) holds automatically
($B = \max_\Omega \Viol < \infty$).
\end{remark}

\subsection{Convergence on General State Spaces}\label{app:convergence}

\begin{lemma}[Existence of Stationary Distribution]\label{lem:stationary}
Under condition~\ref{gen:feller} (weak Feller
property), the Markov chain $\{X_t\}$ on compact metrizable~$\Omega$
admits at least one stationary distribution $\mu^*$.
\end{lemma}

\begin{proof}
On a compact metrizable space, tightness of any sequence of
probability measures is automatic.  The Krylov--Bogoliubov theorem
then applies: the Ces\`{a}ro averages
$\mu_T = T^{-1}\sum_{t=0}^{T-1} \delta_\omega K^t$ admit a
weakly convergent subsequence, and the weak Feller
property~\ref{gen:feller} ensures that any weak limit point is a
stationary distribution.
\end{proof}

\begin{lemma}[Uniqueness and Ergodicity]\label{lem:unique}
Under conditions \ref{gen:drift}--\ref{gen:full-support},
the stationary distribution $\mu^*$ is unique,
and for every initial distribution $\mu_0$:
$\lVert \mu_0 K^t - \mu^* \rVert_{\mathrm{TV}} \to 0$
as $t \to \infty$.
\end{lemma}

\begin{proof}
Condition~\ref{gen:irreducibility} gives $\varphi$-irreducibility.
Condition~\ref{gen:minorization} provides a $1$-small set~$C$.
Condition~\ref{gen:drift} provides a Foster--Lyapunov drift to
the small set~$C$.  By Theorem~16.0.1 of
\citet{meyn1993markov}, a $\varphi$-irreducible chain satisfying
a geometric drift condition toward a small set~$C$ is
\emph{geometrically ergodic}: it admits a unique invariant
probability measure~$\mu^*$, and
$\lVert \mu_0 K^t - \mu^* \rVert_{\mathrm{TV}} \leq M\,r^t$ for
constants $M < \infty$, $r < 1$.
\end{proof}

\begin{lemma}[Concentration Near the Feasible Set]\label{lem:concentration}
For fixed $\epsilon > 0$, the unique stationary distribution
$\mu^*_\epsilon$ satisfies
$\int L(\omega)\, \mu^*_\epsilon(d\omega) \leq b/(1 - \lambda)$.
When the sufficient conditions of \cref{rem:drift-sufficient} hold,
$\int \Viol\, d\mu^*_\epsilon = O(\epsilon)$, and by Markov's
inequality, for any fixed $\delta > 0$:
$\mu^*_\epsilon(\{\omega : \Viol(\omega) > \delta\}) \to 0$
as $\epsilon \to 0$.
\end{lemma}

\begin{proof}
Integrating the drift condition against $\mu^*_\epsilon$:
$\int L\, d\mu^*_\epsilon = \int\!\!\int L(\omega')\, K(\omega,d\omega')\,
\mu^*_\epsilon(d\omega)
\leq \lambda \int L\, d\mu^*_\epsilon + b\, \mu^*_\epsilon(C)
\leq \lambda \int L\, d\mu^*_\epsilon + b$,
giving $\int L\, d\mu^*_\epsilon \leq b/(1-\lambda)$.
\end{proof}

\begin{lemma}[Positive Coherence]\label{lem:coherence}
Let $\mu^*$ be a probability measure on
$\Omega = \prod_{s \in S} D_s$.  If there exist components
$s, s' \in S$ such that the $(s,s')$-marginal
of $\mu^*$ is not a product:
$\mu^*_{s,s'} \neq \mu^*_s \otimes \mu^*_{s'}$,
then $\Coh(\mu^*) > 0$.
\end{lemma}

\begin{proof}
By the data processing inequality:
$\Coh(\mu^*) \geq D_{\mathrm{KL}}(\mu^*_{s,s'} \| \mu^*_s \otimes
\mu^*_{s'}) = I_{\mu^*}(s;\, s') > 0$.
\end{proof}

\subsection{Additional Definitions and Lemmas}\label{app:additional-defs}

\begin{assumption}[Finite coherence regime]\label{asm:finite-coherence}
All stationary measures $\mu^*$ considered satisfy
$\Coh(\mu^*) < \infty$.  This holds automatically in the
discrete case ($|D_s| < \infty$), or whenever $\mu^*$ admits a
density with respect to the product reference measure.
\end{assumption}

\begin{remark}[Stochastic resolution variant]%
\label{rem:stochastic-resolution}
The strict supermartingale condition~\cref{eq:monotone} excludes
kernels that occasionally increase violation.  A relaxed variant
replaces it with a drift-outside-a-set form that connects directly
to the Foster--Lyapunov condition~\ref{gen:drift} on the combined
kernel~$K$.  All convergence results go through under this
relaxation.
\end{remark}

\begin{definition}[Operational Agency]\label{def:operational-agency}
A DCR-system exhibits \emph{operational agency} if the combined
dynamics $K_\epsilon = (1-\epsilon)R + \epsilon\,E$ satisfies
the Foster--Lyapunov drift condition~\ref{gen:drift} toward the
attractor~$\mathcal{A}$.  This makes agency a
substrate-independent dynamical property: outside the compact
``return set,'' the system contracts toward~$\mathcal{A}$ in
expectation.  Every DCR-system satisfying the drift condition
exhibits operational agency by construction.
\end{definition}

\begin{remark}[Annealing variants]\label{rem:annealing}
The fixed-$\epsilon$ analysis can be extended to a cooling
schedule $\epsilon_t \to 0$.  Classical simulated annealing results
\citep{hajek1988cooling} imply convergence of the occupation measures
to a distribution supported on the global minimizers of $\Viol$
under appropriate conditions.
\end{remark}

\begin{remark}[Why DCR dynamics produce non-product stationary measures]%
\label{rem:coherence-application}
The resolution kernel $R$ updates component~$s$ as a function of
its neighbors, introducing statistical dependence.  A product
stationary measure would require this neighbor-dependence to be
exactly cancelled by marginal averaging---a non-generic coincidence.
In each application, the non-product property must be verified for
the specific dynamics at hand.
\end{remark}

\begin{remark}[Heuristic criterion for non-product stationary
measure]\label{rem:non-product-heuristic}
In practice, a non-product stationary distribution
holds whenever the resolution kernel introduces genuine dependence
between neighbors and the exploration kernel does not wash it out.
\end{remark}

% ==========================================================================
\section{Approximate Closure Under Coarse-Graining}\label{app:closure}
% ==========================================================================

This appendix develops the full coarse-graining closure machinery
under timescale separation, disintegration, and lifting regularity
conditions.  The main text (\cref{sec:scale-free}) states an exact
closure theorem for finite lumpable chains; the results below handle
the approximate, continuous-state-space case.

\begin{definition}[Timescale Separation]\label{def:timescale}
Let $\eta > 0$ be a \emph{scale ratio}. We say the micro-dynamics exhibits
$\eta$-\emph{timescale separation} with respect to partition $\pi$ and
compression $\{g_{s'}\}$ if:
\begin{enumerate}[nosep]
  \item \textbf{Fast intra-group mixing.} For each macro-component
    $s' \in S'$, let $\partial s'$ denote the micro-components outside
    $\pi^{-1}(s')$ that share an edge with some component inside
    $\pi^{-1}(s')$ (the \emph{micro-boundary} of group $s'$). For each
    boundary configuration $b_{s'} = (\omega_s)_{s \in \partial s'}$,
    the restricted chain on $\prod_{s \in \pi^{-1}(s')} D_s$ with
    $b_{s'}$ frozen has a unique conditional equilibrium
    $\nu_{s'}(\cdot \mid b_{s'})$ and mixes to this equilibrium in time
    $\tau_{\text{fast}}$.
  \item \textbf{Slow inter-group dynamics.} The inter-group updates (those
    involving edges in $E_{\text{cross}} = \{\{s_1,s_2\} \in E \mid
    \pi(s_1) \neq \pi(s_2)\}$) occur at rate $\eta$ relative to intra-group
    updates.
  \item $\eta\, \tau_{\text{fast}} \to 0$, i.e., fast degrees of freedom
    equilibrate before the next inter-group update.
  \item \textbf{Macro-sufficiency (representative-independence).}
    The expected cross-group violation after fast equilibration depends
    on the macro-boundary alone, not on the specific micro-configuration
    within each group.
\end{enumerate}
\end{definition}

\begin{remark}[Relation to lumpability and conditional independence]%
\label{rem:lumpability}
Condition~4 of \cref{def:timescale} is a form of (approximate)
\emph{lumpability}: the compressed macrostate renders micro-boundary
details conditionally irrelevant for inter-group interactions after
fast equilibration.  This parallels conditional independence
assumptions used in renormalization group methods, Mori--Zwanzig
averaging, and Markov state modelling.
\end{remark}

\begin{definition}[Macro-Violation]\label{def:macro-violation}
Given the conditional equilibria from \cref{def:timescale}, the
\emph{macro-violation} of a macro-configuration
$\tilde{\omega} \in \tilde{\Omega}$ with respect to an inter-group
edge $e' = \{s'_1, s'_2\} \in E'$ is
\begin{equation}\label{eq:macro-violation}
  \tilde{v}_{e'}(\tilde{\omega}_{s'_1}, \tilde{\omega}_{s'_2}) =
  \sum_{\substack{\{s_1,s_2\} \in E_{\text{cross}} \\
  \pi(s_1) = s'_1,\, \pi(s_2) = s'_2}}
  \mathbb{E}_{\nu_{s'_1}(\cdot\,|\,b_{s'_1}) \otimes
  \nu_{s'_2}(\cdot\,|\,b_{s'_2})}
  \bigl[v_{\{s_1,s_2\}}(x_{s_1}, x_{s_2})\bigr].
\end{equation}
The total macro-violation is
$\widetilde{\Viol}(\tilde{\omega}) = \sum_{e' \in E'}
\tilde{v}_{e'}$.
\end{definition}

\begin{lemma}[Effective Markovianity Under Timescale Separation]%
\label{lem:effective-markov}
Under $\eta$-timescale separation and macro-sufficiency
(\cref{def:timescale}), and additionally assuming:
\begin{enumerate}[nosep,label=(M\arabic*)]
  \item\label{cond:uniform-mixing} \textbf{Uniform geometric
    ergodicity of the fast chain.}  For each group $s'$ and boundary
    configuration $b_{s'}$, the restricted intra-group chain mixes
    to $\nu_{s'}(\cdot \mid b_{s'})$ at a geometric rate
    $\rho < 1$ uniformly over $b_{s'}$.
  \item\label{cond:lifting-regularity} \textbf{Lifting kernel
    regularity.}  The product of conditional equilibria admits a
    regular conditional probability (disintegration) with
    respect to the compression~$g$.
\end{enumerate}

\noindent
Define the effective macro transition kernel:
\begin{equation}\label{eq:macro-kernel}
  \tilde{K}(\tilde{\omega}, \tilde{A})
  = \int_{\Omega}
    K_{\text{slow}}(\omega, g^{-1}(\tilde{A}))\;
    \rho_{\tilde{\omega}}(d\omega),
\end{equation}
where $K_{\text{slow}}$ is the micro-kernel restricted to inter-group
updates and $\rho_{\tilde{\omega}}$ is the disintegration measure.

Then, in the limit $\eta\tau_{\text{fast}} \to 0$, the slow-time
macro-process $\{\tilde{X}_k\}$ is a time-homogeneous Markov chain
with kernel~$\tilde{K}$.  For finite timescale separation,
$\{\tilde{X}_k\}$ is approximately Markov with error
$\varepsilon(\eta, \rho) \to 0$ as
$\eta\tau_{\text{fast}} \to 0$.
\end{lemma}

\begin{proof}[Proof sketch]
Under timescale separation, each group equilibrates to
its conditional equilibrium before the next inter-group update.
By uniform geometric mixing and macro-sufficiency, the one-step
transition probability depends only on the current macro-state,
giving Markovianity.  For finite separation, the geometric mixing
bound yields the approximation error.
\end{proof}

\begin{lemma}[Macro-Resolution Inherits Drift]\label{lem:macro-drift}
Under the assumptions of \cref{lem:effective-markov}, and additionally
assuming inter-group contraction:
\begin{enumerate}[nosep,label=(D\arabic*)]
  \item\label{cond:inter-contraction} \textbf{Inter-group contraction.}
    There exists $\alpha > 0$ such that the inter-group resolution kernel
    reduces $\tilde{v}_{e'}$ in expectation uniformly.
\end{enumerate}
Then $\tilde{K}$ satisfies a Foster--Lyapunov drift condition for
$\tilde{L} = \widetilde{\Viol} + 1$.
\end{lemma}

\begin{proof}[Proof sketch]
Under timescale separation, the fast dynamics resolves intra-group
violation; the remaining inter-group violation depends on the
macro-state by macro-sufficiency.  The contraction assumption yields
the drift.
\end{proof}

\begin{lemma}[Macro-Exploration Inherits $\varphi$-Irreducibility]%
\label{lem:macro-explore}
If $K$ is $\varphi$-irreducible with full exploration support, $g$
is continuous and surjective, and the slow-time skeleton includes
inter-group exploration events, then $\tilde{K}$ is
$\tilde{\varphi}$-irreducible on $\tilde{\Omega}$.
\end{lemma}

\begin{proof}
Follows from pushing forward the micro-level irreducibility through
the compression map~$g$.
\end{proof}

\begin{lemma}[Macro-Coherence]\label{lem:macro-coherence}
If $\tilde{\mu}^*$ has a non-product marginal along at least one
macro-edge, then $\Coh(\tilde{\mu}^*) > 0$.
\end{lemma}

\begin{proof}
Direct application of \cref{lem:coherence} to $\tilde{\mu}^*$.
\end{proof}

\begin{theorem}[Closure Under Coarse-Graining (conditional)]%
\label{thm:closure}
Let $\mathcal{C}$ be a cognitive system, $\pi : S \twoheadrightarrow S'$
a partition map, and $\{g_{s'}\}$ compression maps with continuous,
surjective $g : \Omega \to \tilde{\Omega}$. If:
\begin{enumerate}[nosep]
  \item[(i)] The micro-dynamics exhibits $\eta$-timescale separation
    with uniform geometric mixing~\ref{cond:uniform-mixing} and lifting
    kernel regularity~\ref{cond:lifting-regularity}.
  \item[(ii)] The macro-constraint graph $G'$ is connected.
  \item[(iii)] The macro-feasible set is non-empty and compact,
    the inter-group resolution satisfies
    contraction~\ref{cond:inter-contraction}, and
    $\tilde{\mu}^*$ has a non-product marginal along at least one
    macro-edge.
  \item[(iv)] The effective macro kernel $\tilde{K}$ is weak Feller
    and admits a minorization on a compact sublevel set.
\end{enumerate}
Then $\tilde{\mathcal{C}} = \Gamma_{\pi,g}(\mathcal{C})$ is a cognitive
system on $\tilde{\Omega}$.
\end{theorem}

\begin{proof}[Proof (structural argument)]
We verify each component of a cognitive system for
$\tilde{\mathcal{C}}$:
the constraint network is well-defined by \cref{ssec:closure};
exploration follows from \cref{lem:macro-explore};
resolution from \cref{lem:macro-drift};
and coherence from \cref{lem:macro-coherence}.
Applying the convergence theorem to the macro-system on
$\tilde{\Omega}$ completes the verification.
\end{proof}

\begin{remark}[Logical status of the closure theorem]%
\label{rem:closure-scope}
The closure theorem is conditional: it shows that \emph{if}
coarse-graining yields an effective Markov macro-model satisfying
DCR-type conditions, \emph{then} the macro-model is a DCR-system.
Two concrete classes where the assumptions are standard:
\begin{enumerate}[nosep]
  \item \emph{Finite-state chains with exact lumpability}
    (Kemeny--Snell)---the closure is exact.
  \item \emph{Metastable Markov state models}---the closure
    holds approximately, with error controlled by the spectral gap
    ratio.
\end{enumerate}
\end{remark}

% ==========================================================================
\section{Additional Remarks and Extensions}\label{app:remarks}
% ==========================================================================

This appendix collects remarks and extensions that, while valuable
for a complete picture, are not essential to the main argument.

\begin{remark}[Engineering witness: consensus as DCR]%
\label{rem:consensus-witness}
Distributed consensus protocols provide an instructive engineering
witness for DCR\@.  In replicated-state-machine settings,
independent agents maintain local copies of a shared state and must
reconcile conflicting updates (e.g., competing spends) without a
central controller.  A natural strategy is to allow local proposal,
temporary branching into mutually incompatible candidate evolutions,
and subsequent convergence via a selection rule informed by delayed
nonlocal information.  Read through the DCR lens: proposal
corresponds to exploration, local validity checks and compatibility
propagation correspond to distributed constraint resolution, and
eventual agreement on a single ledger state is a coherent
attractor.  We emphasize this is a \emph{witness} rather than a
reduction: the purpose is to exhibit a familiar, explicitly
mechanistic system where global coherence arises from local
constraint processing under partial information.
\end{remark}

\begin{remark}[Engineering witness: self-play as DCR]%
\label{rem:selfplay}
Self-play in machine learning provides a second engineering witness:
rollouts generate a branching space of candidate trajectories
(exploration), credit assignment and constraint propagation prune
or reweight trajectories (resolution), and training concentrates on
stable policy attractors (stabilization).  This is a witness, not a
reduction; the point is that global coherence can arise from local
update rules under delayed, nonlocal feedback, paralleling
\cref{rem:consensus-witness} and the branch-selection picture in
\cref{rem:collapse-selection}.
\end{remark}

\begin{remark}[Finiteness of $S$]\label{rem:finiteness}
The formal development assumes $|S| < \infty$. This suffices for systems
with a natural decomposition into discrete components (particles, neurons,
organisms) but appears to exclude continuum field theories. The physical
examples in \cref{sec:physics} (e.g., fluid parcels in convection) should
be read as finite-element discretizations of the underlying continuum; the
formal extension to countable or measure-theoretic component spaces
(replacing sums with integrals in \cref{eq:violation,eq:edge-coherence}) is
straightforward but introduces technical regularity conditions that we
defer to future work.

We note, however, that the discreteness assumption may be less restrictive
than it appears.  There exist proposals in which the continuum structure
of standard quantum mechanics is not fundamental but emergent from a
discrete substrate.  \citet{powers2024statistical} construct a model
built entirely from finite binary sequences that reproduces the
probability distributions of canonical quantum mechanics, with small
deviations at finite~$n$ that shrink as $n$ increases.  For
any finite~$n$ the system is a finite constraint network in the sense of
\cref{def:constraint-network}; the continuum of canonical quantum theory
is recovered only in the limit.  This suggests that the continuum
structure of standard physics may be an idealization of a fundamentally
discrete substrate---precisely the kind of substrate that DCR is designed
to describe (see \cref{rem:micro-choices}).
\end{remark}

\begin{remark}[Branching exploration variant]\label{rem:branching-explore}
In some domains it is natural to treat exploration not as additive
noise but as \emph{branching}: from a given configuration, the
system generates a family of candidate next states (a ``multiway''
step), temporarily maintaining a set of possible evolutions.
Constraint resolution then prunes or reweights these branches, and
stabilization corresponds to selecting (or concentrating on) a
single consistent history.  The Markov-kernel formalism still
applies by viewing a branching--selection step as an induced
stochastic kernel obtained by marginalizing over the latent branch
variable.
\end{remark}

\begin{remark}[Coherence in the unique-attractor limit]%
\label{rem:coherence-delta}
If the feasible set $\mathcal{F}$ is a singleton
$\{\omega^\star\}$ and $\mu^*_\epsilon \to \delta_{\omega^\star}$
as $\epsilon \to 0$, then $\Coh(\delta_{\omega^\star}) = 0$
(each marginal is a point mass and the product of marginals
equals~$\mu^*$).  This is not a defect but a feature of the
framework's design: the coherence condition $\Coh_E(\mu_\epsilon)
> 0$ is evaluated at \emph{fixed} $\epsilon > 0$, where the
stationary measure retains genuine statistical spread due to ongoing
exploration.  A system with $\epsilon = 0$ has no exploration and is
therefore not a DCR-system (\cref{def:dcr-system}).  In the
fixed-$\epsilon$ regime, if the stationary distribution has any
non-product edge marginal, then $\Coh_E(\mu_\epsilon) > 0$.
\end{remark}

\begin{remark}[Alternative coordination witnesses]%
\label{rem:alt-coherence}
The main text uses edge-sum mutual information
$\Coh_E(\mu) = \sum_{\{s,s'\} \in E} I_\mu(X_s; X_{s'})$
as the coherence witness (\cref{def:coherence}).  Other choices work
equally well:
\begin{enumerate}[nosep]
  \item \emph{Total correlation (multi-information):}
    $\Coh(\mu) = D_{\mathrm{KL}}(\mu \,\|\, \bigotimes_s \mu_s)$,
    which upper-bounds $\Coh_E$ and is used in the IIT recovery
    (\cref{prop:iit}).
  \item \emph{Cut-based dependence measures} that quantify
    information loss under graph partitions (e.g., graph-cut
    multi-information).
\end{enumerate}
All results that use coherence as a \emph{witness} go through with
any nonnegative dependence functional that vanishes on product measures
and is positive whenever a non-product marginal exists.  The specific
choice is not essential to the framework.
\end{remark}

\begin{remark}[Relation to optimization and computer science]%
\label{rem:optimization-cs}
The Ising example makes explicit the connection between DCR and
classical optimization/constraint-satisfaction frameworks.
\emph{Simulated annealing}
\citep{hajek1988cooling} is a DCR dynamics where $\epsilon$
(temperature) is decreased over time, driving the system toward
global violation minimizers.  \emph{Belief propagation} and
message-passing algorithms for random constraint satisfaction
problems \citep{mezard2002random} implement distributed resolution:
each variable node updates its marginal based on neighboring
constraints, a process structurally identical to the resolution
kernel~$R$.  More broadly, any local-search heuristic for
combinatorial constraint satisfaction (SAT, CSP, graph coloring)
instantiates the exploration--resolution interplay.  DCR does not
claim novelty in these algorithms; it claims that the
\emph{same formal triad} appears in physical, biological, and
cognitive systems, not only in engineered solvers.
\end{remark}

\begin{remark}[Collapse as selection over branches]%
\label{rem:collapse-selection}
A complementary structural picture treats quantum ``collapse'' as
selection over a branching space of candidate transactions
(cf.\ \cref{rem:branching-explore}).  An emission event generates a
set of potential absorber-matched outcomes (branches); confirmation
waves implement distributed feasibility checks; and the realized
event corresponds to selecting a branch once sufficiently global
consistency information is available.  The selection can appear
retrocausal because the constraints relevant to branch feasibility
depend on spacelike-separated absorbers whose responses are only
available after finite propagation delays.  This provides an
engineering-style intuition for why ``late'' information can fix an
``earlier'' outcome without invoking a centralized chooser.
\end{remark}

\begin{remark}[Constraint-mediated selection]%
\label{rem:constraint-mediated-selection}
The recurring pattern across physical scales can be distilled into an
abstract selection template:
\begin{enumerate}[nosep]
  \item \emph{Variation} --- the exploration kernel~$E$ generates a
        population of candidate configurations.
  \item \emph{Constraint filtering} --- the resolution dynamics~$R$
        retains configurations that locally reduce constraint violations.
  \item \emph{Retention / stabilization} --- surviving configurations
        accumulate near the coherent attractor~$\mathcal{A}$, which
        acts as the long-run ``memory'' of the process.
\end{enumerate}
We call this \emph{constraint-mediated selection} rather than
``natural selection'' to emphasize that the filtering step is
driven by compatibility constraints on the network, not by
reproductive fitness specifically.  Darwinian selection is the
biological instance; quantum collapse is the physical instance;
simulated annealing is the computational instance.  In each case,
the formal structure is the same DCR triad.
\end{remark}

\begin{remark}[Interpretation-independence and decoherence witness]%
\label{rem:interpretation-independence}
The DCR mapping does not depend on retrocausality.  TIQM is used
in \cref{ssec:quantum} because the constraint-satisfaction structure
is explicit in that formulation; no claim is made that TIQM is
correct or that DCR solves the measurement problem.

A second, less interpretationally loaded witness uses
\emph{decoherence and einselection}
\citep{zurek2003decoherence}.  In this framing: (i)~\emph{exploration}
is the unitary spreading of the system--environment state over the
full Hilbert space; (ii)~\emph{resolution} is the
environment-induced suppression of off-diagonal coherences---a
local, distributed process in which each environmental degree of
freedom independently constrains the system's phase relations;
(iii)~\emph{stabilization} is einselection: the emergence of
pointer states as the unique basis robust to ongoing
decoherence---the coherent attractor of the DCR triad.  This
mapping avoids retrocausality entirely and relies only on standard
open-quantum-systems theory; it does not, however, address the
``definite outcome'' question (the same limitation as decoherence
itself).  The two witnesses are complementary: TIQM makes the
constraint-satisfaction structure vivid; decoherence makes the
distributional character of resolution rigorous.
\end{remark}

\begin{remark}[Unpredictability and tie-breaking]\label{rem:tiebreak}
In distributed constraint-resolution problems with delayed nonlocal
inputs, the outcome can be unpredictable even when the local rules
are fixed: the relevant constraints are not simultaneously available
at any single location.  In such settings, stochasticity can be
interpreted operationally as a symmetry-breaking device among
near-equally feasible resolutions, rather than as ``unstructured
noise.''  This perspective is compatible with the DCR formalism: it
amounts to placing the stochasticity in the resolution kernel (or
in the branch-selection kernel of
\cref{rem:branching-explore,rem:collapse-selection}) rather than
exclusively in the exploration kernel.
\end{remark}

\begin{remark}[Discrete ontic structure and micro-choices]\label{rem:micro-choices}
The DCR picture of quantum mechanics does not require the continuum
structure of canonical quantum theory.
\citet{powers2024statistical} model measurement events as event
networks whose nodes and edges are built from finite base-2 (and
base-4/base-16) symbol sequences with XOR-like (addition modulo two)
composition.  Observable quantum numbers correspond to symbol
\emph{counts}---coarse summaries of the underlying sequences---while
the ordering of symbols within each sequence remains hidden.  This
hidden ordering is the source of non-determinism (in their phrase:
``counts are generally observable, but sequences are not'')
\citep{powers2024statistical}.

In DCR terms, the space of admissible ontic configurations (all
symbol orderings consistent with the quantum numbers) is the
\emph{exploration space}; the contextual compatibility
conditions---which orderings are consistent with both observers'
measurement events---are the \emph{constraints}; and the observed
probability distribution, given by relative frequencies of surviving
configurations, is the \emph{stabilized pattern}.  The individual
symbol orderings are \emph{micro-choices}: local, hidden degrees of
freedom whose structured resolution produces the macroscopic outcome.

For finite sequence length~$n$, the model predicts small but
unavoidable deviations from canonical QM due to discrete granularity
(e.g., rotation angles are effectively rational-valued), with
improved agreement as~$n$ increases.  \citet{powers2024statistical}
propose optical tabletop tests to constrain these $n$-dependent
deviations.  Since all empirical measurement data is inherently
discrete, the finite-$n$ model is not merely an approximation to
the continuous theory but a plausible candidate for a more
fundamental description.  If this view is correct, it supports the
DCR framework's assumption of finite discrete components
(\cref{rem:finiteness}): the continuum would be an idealization of
an underlying discrete constraint resolution process operating
through micro-choices.
\end{remark}

\begin{remark}[Proof-sketch character of the B{\'e}nard verification]%
\label{rem:benard-caveat}
Three aspects of the verification in \cref{ex:benard} merit further
care in a fully rigorous treatment.  (i)~The constraints should be
read as local consistency conditions of the \emph{discretized
time-step update}: at each step the violation functional measures the
residual of the one-step Boussinesq update, not the steady-state PDE
residual.  The drift argument then requires that the discretized
update reduces this residual on average---a statement about the
time-stepping scheme, not about the energy functional of the PDE
directly.  The transfer from the energy functional $\mathcal{E}$ to
$\Viol$ near the attractor requires comparability of their
respective Hessians under the linearized Boussinesq operator---a
standard result in discretized Navier--Stokes stability theory, but
one whose constants depend on the lattice spacing~$h$.
(ii)~The projection $\Pi_\Omega$ onto the compact box breaks the
smoothness of the Gaussian exploration kernel at the boundary
of~$\Omega$; hence the ``continuous and positive'' density claim in
the minorization step holds only on the interior, and a boundary
layer analysis is needed to establish the minorization uniformly
on the sublevel set~$C$.
(iii)~The spectral gap $\lambda_1$ of the graph Laplacian depends on
the lattice discretization, and the drift constants
$\lambda, b$ depend on $h$ and $N$; the verification is for a fixed
discretization and does not address the continuum limit $h \to 0$.
These issues are standard in the numerical analysis of stochastic
PDE discretizations; we highlight them to be explicit about the
level of rigor.  The example should be read as a detailed
\emph{verification sketch} exhibiting the structural
correspondence between B\'enard convection and the DCR axioms, not
as a fully rigorous proof.
\end{remark}

\begin{remark}[Related formal program: neural-network universe]%
\label{rem:nn-universe}
\citet{vanchurin2020world} proposes that the universe at its most
fundamental level is a neural network with two tiers of dynamical
degrees of freedom: \emph{trainable variables} (weights, biases) and
\emph{hidden variables} (neuron states).  He shows that near
equilibrium, the trainable-variable dynamics is well approximated by
Madelung/Schr\"odinger-type equations (with free energy playing the
role of the phase), while further from equilibrium the same dynamics
yields Hamilton--Jacobi behavior.  In a coarse-grained limit, the
hidden-variable dynamics can produce emergent relativistic strings and,
via an Onsager-symmetry argument for entropy production, an
Einstein--Hilbert-like gravitational term.  This is a concrete instance
of distributed constraint resolution producing stable macroscopic
laws.  We treat such ``neural-network universe'' models as
substrate-specific realizations of DCR rather than competitors.
\end{remark}

\begin{remark}[Computability of depth]\label{rem:depth-computability}
Computing $\delta(\mathcal{C})$ exactly requires optimizing over all
hierarchical partition sequences $(\pi_1, \ldots, \pi_k)$ and compression
maps $(g_1, \ldots, g_k)$, verifying the DCR conditions at each
level---a combinatorially intractable problem in general.  In practice,
$\delta$ serves as a coarse ordinal ranking rather than a precise cardinal
measure: distinguishing depth~2 from depth~6 is meaningful; distinguishing
depth~6 from depth~7 requires detailed empirical verification of the DCR
triad at each level.
\end{remark}

\begin{remark}[IIT versions]\label{rem:iit-versions}
The recovery in \cref{prop:iit} targets IIT~2.0, which uses KL
divergence as its distance measure. IIT~3.0
\citep{tononi2016integrated} replaces KL divergence with the earth
mover's distance (Wasserstein metric) and defines $\Phi$ over
cause--effect structures rather than single distributions. The
structural relationship---$\Phi$ as irreducible coherence---still
holds conceptually, but the formal identity with DCR's $\Coh$
requires additional metric-space machinery that we do not develop
here. IIT~4.0 further introduces dynamical aspects that bring it
closer to DCR's process-level account.
\end{remark}

\begin{remark}[Optional optimization reading]\label{rem:optimization-reading}
An optional interpretive strengthening is to view the DCR process as
optimizing a system-level functional: exploration generates candidate
interactions, and resolution selects those that maximize realized
interaction (information exchange) subject to local conservation
constraints.  This reading aligns DCR with ubiquitous variational
principles (least/stationary action) at the level of metaphor and
motivation, but it is \emph{not} assumed by the formal results:
the theorems require only local violation-reduction and ergodic
exploration, not a globally computed objective.
\end{remark}

\begin{remark}[Transactional density as a witness]%
\label{rem:tx-density}
In many substrates, one can define a \emph{transaction} as an event
in which distributed constraints are jointly satisfied across an
interface (e.g., emitter--absorber completion, message commit in
consensus, trade execution).  The \emph{transactional
density}~$\rho_\tau$ is the rate (or expected count) of such events
in the stabilized regime.  DCR does not assume that physical
dynamics maximizes transactional density, but $\rho_\tau$ can serve
as an empirical \emph{witness} correlated with coherence and
persistence in self-organizing systems.
\end{remark}

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}

